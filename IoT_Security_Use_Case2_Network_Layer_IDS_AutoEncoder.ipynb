{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "IoT-Security-Use-Case2-Network-Layer-IDS-AutoEncoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwangliberty/AIoTDesign-Frontend/blob/master/IoT_Security_Use_Case2_Network_Layer_IDS_AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAlmdQ6wA135"
      },
      "source": [
        "# Chapter 7: IoT Security"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BIzu6zCA138"
      },
      "source": [
        "# Use Case 2: Network Intrusion Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsGWYoeFA139"
      },
      "source": [
        "# Model: Autoencoder (AE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ_xsEp9A13-"
      },
      "source": [
        "# Step 1: Data Collection (downloading)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oct8KUGsA13_"
      },
      "source": [
        "For this use case we are using famus opensource KDDCUP99 data. Please go to this link http://kdd.ics.uci.edu/databases/kddcup99/ and download kddcup.data_10_percent.gz dataset, and save into your preferred folder for further use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MElzyC0DCzkN",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "d1d8af72-9e2b-4e9f-fe5e-8f60ae91a647"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1a07b3eb-846f-4f98-84e9-e76435c66855\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1a07b3eb-846f-4f98-84e9-e76435c66855\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kddcup.data_10_percent.csv to kddcup.data_10_percent.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJdBK07QA14A"
      },
      "source": [
        "# Step 2: Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0f8AhDvA14C"
      },
      "source": [
        "# Splitting of the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOaLTCf_A14D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "637c4079-f497-4780-f3b0-e894aca6bf6a"
      },
      "source": [
        "#Load the Entire Data\n",
        "\n",
        "#Importing all the required Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "IDSdata = pd.read_csv(\"kddcup.data_10_percent.csv\",header = None,engine = 'python',sep=\",\")\n",
        "\n",
        "# Add column header \n",
        "\n",
        "IDSdata.columns = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragement\",\n",
        "                   \"urgent\",\n",
        "                  \"hot\",\"num_failed_logins\",\"logged_in\",\"num_compressed\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
        "                   \"num_file_creations\",\n",
        "                  \"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\"is_hot_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
        "                  \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\n",
        "                   \"srv_diff_host_rate\",\"dst_host_count\",\n",
        "                  \"dst_host_srv_count\",\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
        "                   \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\n",
        "                  \"dst_host_srv_rerror_rate\",\"labels\"]\n",
        "\n",
        "# Explore the Application Layer IDS Data\n",
        "\n",
        "ApplicationLayer = IDSdata[(IDSdata['labels'].isin(['normal.','smurf.','back.','satan.','pod.','guess_passwd.','buffer_overflow.',\n",
        "                                                    'warezmaster.','imap.','loadmodule.','ftp_write.','multihop.','perl.']))]\n",
        "print (ApplicationLayer['labels'].value_counts())\n",
        "\n",
        "# Save a Applayer data only into a text file\n",
        "ApplicationLayer.to_csv('Final_App_Layer.txt',header = None,index = False)\n",
        "\n",
        "# Explore the Transport Layer IDS Data\n",
        "TransportLayer = IDSdata[(IDSdata['labels'].isin(['normal.','neptune.','portsweep.','teardrop.','buffer_overflow.',\n",
        "                                                 'land.','nmap.']))]\n",
        "print (TransportLayer['labels'].value_counts())\n",
        "TransportLayer.to_csv('Final_Transport_Layer.txt',header = None,index = False)\n",
        "\n",
        "# Explore the Network Layer IDS Data\n",
        "NetworkLayer = IDSdata[(IDSdata['labels'].isin(['normal.','smurf.','ipsweep.','pod.','buffer_overflow.']))]\n",
        "print (NetworkLayer['labels'].value_counts())\n",
        "NetworkLayer.to_csv('Final_Network_Layer.txt',header = None,index = False)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "smurf.              280790\n",
            "normal.              97278\n",
            "back.                 2203\n",
            "satan.                1589\n",
            "pod.                   264\n",
            "guess_passwd.           53\n",
            "buffer_overflow.        30\n",
            "warezmaster.            20\n",
            "imap.                   12\n",
            "loadmodule.              9\n",
            "ftp_write.               8\n",
            "multihop.                7\n",
            "perl.                    3\n",
            "Name: labels, dtype: int64\n",
            "neptune.            107201\n",
            "normal.              97278\n",
            "portsweep.            1040\n",
            "teardrop.              979\n",
            "nmap.                  231\n",
            "buffer_overflow.        30\n",
            "land.                   21\n",
            "Name: labels, dtype: int64\n",
            "smurf.              280790\n",
            "normal.              97278\n",
            "ipsweep.              1247\n",
            "pod.                   264\n",
            "buffer_overflow.        30\n",
            "Name: labels, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnywwKYVA0wY",
        "outputId": "50f8be86-7977-4bf3-fc57-23a963dcbe54"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final_App_Layer.txt\t Final_Transport_Layer.txt   sample_data\n",
            "Final_Network_Layer.txt  kddcup.data_10_percent.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pIrsVbrA14H"
      },
      "source": [
        "# Duplicate data removal, categorical data conversion and normalisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIrIVNQVA14I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90c0534-1fb3-40f6-a6b6-c19e8287bb9e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "\n",
        "## For OMP error\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "# Functions for DataLoading and pre-processing\n",
        "\n",
        "def DataLoading (mypath):\n",
        "    print (\"Loading the data\")\n",
        "    dataframe = pd.read_csv(mypath,header = None,engine = 'python',sep=\",\")\n",
        "    return dataframe\n",
        "\n",
        "def DataPreprocessing(mydataframe):\n",
        "    \n",
        "    # Dropping the duplicates\n",
        "    recordcount = len(mydataframe)\n",
        "    print (\"Original number of records in the training dataset before removing duplicates is: \" , recordcount)\n",
        "    mydataframe.drop_duplicates(subset=None, inplace=True)  # Python command to drop duplicates\n",
        "    newrecordcount = len(mydataframe)\n",
        "    print (\"Number of records in the training dataset after removing the duplicates is :\", newrecordcount,\"\\n\")\n",
        "\n",
        "    #Dropping the labels to a different dataset which is used to train the recurrent neural network classifier\n",
        "    df_X = mydataframe.drop(mydataframe.columns[41],axis=1,inplace = False)\n",
        "    df_Y = mydataframe.drop(mydataframe.columns[0:41],axis=1, inplace = False)\n",
        "\n",
        "    # Convert Categorial data to the numerical data for the efficient classification\n",
        "    df_X[df_X.columns[1:4]] = df_X[df_X.columns[1:4]].stack().rank(method='dense').unstack()\n",
        "    \n",
        "    # Coding the normal as \" 1 0\" and attack as \"0 1\"\n",
        "    df_Y[df_Y[41]!='normal.'] = 0\n",
        "    df_Y[df_Y[41]=='normal.'] = 1\n",
        "    #print (labels[41].value_counts())\n",
        "    \n",
        "    #converting input data into float which is requried in the future stage of building in the network\n",
        "    df_X = df_X.loc[:,df_X.columns[0:41]].astype(float)\n",
        "\n",
        "    # Normal is \"1 0\" and the abnormal is \"0 1\"\n",
        "    df_Y.columns = [\"y1\"]\n",
        "    df_Y.loc[:,('y2')] = df_Y['y1'] ==0\n",
        "    df_Y.loc[:,('y2')] = df_Y['y2'].astype(int)\n",
        "    \n",
        "    return df_X,df_Y\n",
        "\n",
        "print (\"Laoding the IDS Data\")\n",
        "#data_path = \"Final_App_Layer.txt\" # If you want to use for Applicaiton Layer\n",
        "#data_path = \"Final_Transport_Layer.txt\" # If you want to use for Transport Layer\n",
        "data_path = \"Final_Network_Layer.txt\" # If you want to use for Network Layer\n",
        "\n",
        "dataframe = DataLoading(data_path)\n",
        "\n",
        "print (\"Data Preprocessing of loaded IDS Data\")\n",
        "data_X, data_Y = DataPreprocessing(dataframe)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Laoding the IDS Data\n",
            "Loading the data\n",
            "Data Preprocessing of loaded IDS Data\n",
            "Original number of records in the training dataset before removing duplicates is:  379609\n",
            "Number of records in the training dataset after removing the duplicates is : 89360 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDjpzNAZA14M"
      },
      "source": [
        "# Feature selection (optional pre-processing, but useful for network size)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1v268tTA14M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "2f15e4c4-3cea-4328-9741-ada2c599e80d"
      },
      "source": [
        "##### Function for features selection for the Model Training\n",
        "\n",
        "def FeatureSelection(myinputX, myinputY):\n",
        "\n",
        "    labels = np.array(myinputY).astype(int)\n",
        "    inputX = np.array(myinputX)\n",
        "    \n",
        "    #Random Forest Model\n",
        "    model = RandomForestClassifier(random_state = 0)\n",
        "    model.fit(inputX,labels)\n",
        "    importances = model.feature_importances_\n",
        "    \n",
        "    \n",
        "    #Plotting the Features agains their importance scores\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "    std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
        "             axis=0)\n",
        "    plt.figure(figsize = (10,5))\n",
        "    plt.title(\"Feature importances (y-axis) vs Features IDs(x-axis)\")\n",
        "    plt.bar(range(inputX.shape[1]), importances[indices],\n",
        "       color=\"b\", yerr=std[indices], align=\"center\")\n",
        "    plt.xticks(range(inputX.shape[1]), indices)\n",
        "    plt.xlim([-1, inputX.shape[1]])\n",
        "    plt.show()\n",
        "    \n",
        "    # Selecting top featueres which have higher importance values = here we can find \"12\" features\n",
        "    #as we can see in the next step\n",
        "    newX = myinputX.iloc[:,model.feature_importances_.argsort()[::-1][:12]]\n",
        "   # Converting the X dataframe into tensors\n",
        "    myX = newX.to_numpy()\n",
        "    myY = labels\n",
        "\n",
        "    return myX,myY\n",
        "\n",
        "## Visualise the data for feature selction\n",
        "    \n",
        "\n",
        "print (\"Performing the Feature Selection on the train data set\")\n",
        "reduced_X,reduced_Y = FeatureSelection(data_X,data_Y)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing the Feature Selection on the train data set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEX-VcJ3A14P"
      },
      "source": [
        "# Step 3: Model Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dllLyIulA14Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a823eb57-721f-4658-dcbf-77f6e10c03a9"
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l1\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import load_model\n",
        "\n",
        "# Train features and Train Labels\n",
        "train_X = reduced_X[:8000]\n",
        "train_Y = reduced_Y[:8000]\n",
        "\n",
        "#Test Features and Test Labels\n",
        "test_X = reduced_X[8001:10000]\n",
        "test_Y = reduced_Y[8001:10000]\n",
        "\n",
        "\n",
        "print (\"Train X shape is :\", train_X.shape)\n",
        "print (\"Train Y shape is :\", train_Y.shape)\n",
        "print (\"Test X shape is :\", test_X.shape)\n",
        "print (\"Test Y shape is :\", test_Y.shape)\n",
        "\n",
        "## Normalizing the Input Features: Using tensorflow normalizing function\n",
        "\n",
        "# Before normalizing, the array of input features should be converted to a dataframe\n",
        "semitrain_X = pd.DataFrame(train_X)\n",
        "semitest_X = pd.DataFrame(test_X)\n",
        "#Importing Scikit learn libraries\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "#Normalizing Train Data Features\n",
        "scaler_traindata = scaler.fit(semitrain_X)\n",
        "train_norm = scaler_traindata.transform(semitrain_X)\n",
        "X_train=train_norm_X = pd.DataFrame(train_norm)\n",
        "\n",
        "#Normalizing Test Data Features\n",
        "scaler_testdata = scaler.fit(semitest_X)\n",
        "test_norm = scaler_testdata.transform(semitest_X)\n",
        "X_test=test_norm_X = pd.DataFrame(test_norm)\n",
        "#Testing/Training Data\n",
        "Y_train=train_Y\n",
        "Y_test=test_Y\n",
        "# Useful paprameters for the Autoencoder\n",
        " # dimension one one input data\n",
        "input_dim = X_train.shape[1]\n",
        "# this is the size of our encoded representations\n",
        "encoding_dim = 32 \n",
        "    \n",
        "## For OMP error\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=l1(10e-5))(input_layer)\n",
        "encoder = Dense(int(encoding_dim), activation=\"relu\")(encoder)\n",
        "encoder = Dense(int(encoding_dim-2), activation=\"relu\")(encoder)\n",
        "code = Dense(int(encoding_dim-4), activation='tanh')(encoder)\n",
        "decoder = Dense(int(encoding_dim-2), activation='tanh')(code)\n",
        "decoder = Dense(int(encoding_dim), activation='tanh')(encoder)\n",
        "decoder = Dense(input_dim, activation='relu')(decoder)\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "\n",
        "## Parameters for Model configuration and saving \n",
        "nb_epoch = 100\n",
        "batch_size = 60\n",
        "autoencoder.compile(optimizer='adam',\n",
        "                    loss='mean_squared_error',\n",
        "                    metrics=['accuracy'])\n",
        "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
        "                               verbose=0,\n",
        "                               save_best_only=True)\n",
        "                               \n",
        "tensorboard = TensorBoard(log_dir='./logs',\n",
        "                          histogram_freq=0,\n",
        "                          write_graph=True,\n",
        "                          write_images=True)\n",
        "history = autoencoder.fit(X_train, X_train,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_test, X_test),\n",
        "                    verbose=1,\n",
        "                    callbacks=[checkpointer, tensorboard]).history\n",
        "                                                \n",
        "\n",
        "autoencoder = load_model('model.h5')\n",
        "predictions = autoencoder.predict(X_test)\n",
        "mse = np.mean(np.power(X_test - predictions, 2), axis=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train X shape is : (8000, 12)\n",
            "Train Y shape is : (8000, 2)\n",
            "Test X shape is : (1999, 12)\n",
            "Test Y shape is : (1999, 2)\n",
            "Epoch 1/100\n",
            "134/134 [==============================] - 1s 5ms/step - loss: 0.1002 - accuracy: 0.3922 - val_loss: 0.0132 - val_accuracy: 0.8834\n",
            "Epoch 2/100\n",
            "134/134 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.7199 - val_loss: 0.0133 - val_accuracy: 0.9365\n",
            "Epoch 3/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.7438 - val_loss: 0.0333 - val_accuracy: 0.9655\n",
            "Epoch 4/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.7856 - val_loss: 0.0245 - val_accuracy: 0.9605\n",
            "Epoch 5/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.7873 - val_loss: 0.0227 - val_accuracy: 0.9650\n",
            "Epoch 6/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.7892 - val_loss: 0.0222 - val_accuracy: 0.9595\n",
            "Epoch 7/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 0.7959 - val_loss: 0.0216 - val_accuracy: 0.8504\n",
            "Epoch 8/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.7952 - val_loss: 0.0216 - val_accuracy: 0.8299\n",
            "Epoch 9/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.7964 - val_loss: 0.0219 - val_accuracy: 0.7859\n",
            "Epoch 10/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.7918 - val_loss: 0.0226 - val_accuracy: 0.7214\n",
            "Epoch 11/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.7978 - val_loss: 0.0222 - val_accuracy: 0.6898\n",
            "Epoch 12/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.8008 - val_loss: 0.0220 - val_accuracy: 0.7009\n",
            "Epoch 13/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.8079 - val_loss: 0.0227 - val_accuracy: 0.6898\n",
            "Epoch 14/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.8069 - val_loss: 0.0226 - val_accuracy: 0.6788\n",
            "Epoch 15/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.7936 - val_loss: 0.0233 - val_accuracy: 0.6733\n",
            "Epoch 16/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.8054 - val_loss: 0.0241 - val_accuracy: 0.6728\n",
            "Epoch 17/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.8203 - val_loss: 0.0247 - val_accuracy: 0.6763\n",
            "Epoch 18/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.8157 - val_loss: 0.0254 - val_accuracy: 0.6728\n",
            "Epoch 19/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.8138 - val_loss: 0.0256 - val_accuracy: 0.6713\n",
            "Epoch 20/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 9.4510e-04 - accuracy: 0.8224 - val_loss: 0.0254 - val_accuracy: 0.6643\n",
            "Epoch 21/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 8.9479e-04 - accuracy: 0.8062 - val_loss: 0.0255 - val_accuracy: 0.6768\n",
            "Epoch 22/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 8.5973e-04 - accuracy: 0.8208 - val_loss: 0.0268 - val_accuracy: 0.6558\n",
            "Epoch 23/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 8.8299e-04 - accuracy: 0.8111 - val_loss: 0.0263 - val_accuracy: 0.6518\n",
            "Epoch 24/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 9.6343e-04 - accuracy: 0.8210 - val_loss: 0.0266 - val_accuracy: 0.6693\n",
            "Epoch 25/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 9.7289e-04 - accuracy: 0.8152 - val_loss: 0.0270 - val_accuracy: 0.6648\n",
            "Epoch 26/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 9.1027e-04 - accuracy: 0.8029 - val_loss: 0.0277 - val_accuracy: 0.6473\n",
            "Epoch 27/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 8.2134e-04 - accuracy: 0.8181 - val_loss: 0.0283 - val_accuracy: 0.6523\n",
            "Epoch 28/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 9.2979e-04 - accuracy: 0.8164 - val_loss: 0.0283 - val_accuracy: 0.6578\n",
            "Epoch 29/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 8.2863e-04 - accuracy: 0.8060 - val_loss: 0.0287 - val_accuracy: 0.6633\n",
            "Epoch 30/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 9.8543e-04 - accuracy: 0.8171 - val_loss: 0.0266 - val_accuracy: 0.6648\n",
            "Epoch 31/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 9.3547e-04 - accuracy: 0.8130 - val_loss: 0.0292 - val_accuracy: 0.6578\n",
            "Epoch 32/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 9.5769e-04 - accuracy: 0.8052 - val_loss: 0.0282 - val_accuracy: 0.6653\n",
            "Epoch 33/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 9.2108e-04 - accuracy: 0.8051 - val_loss: 0.0278 - val_accuracy: 0.6793\n",
            "Epoch 34/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 8.9854e-04 - accuracy: 0.8084 - val_loss: 0.0255 - val_accuracy: 0.6768\n",
            "Epoch 35/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.3072e-04 - accuracy: 0.7929 - val_loss: 0.0265 - val_accuracy: 0.6758\n",
            "Epoch 36/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.9434e-04 - accuracy: 0.8111 - val_loss: 0.0251 - val_accuracy: 0.6603\n",
            "Epoch 37/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.4146e-04 - accuracy: 0.8202 - val_loss: 0.0257 - val_accuracy: 0.6518\n",
            "Epoch 38/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.9943e-04 - accuracy: 0.8190 - val_loss: 0.0254 - val_accuracy: 0.6513\n",
            "Epoch 39/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.6467e-04 - accuracy: 0.8088 - val_loss: 0.0242 - val_accuracy: 0.6398\n",
            "Epoch 40/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.0343e-04 - accuracy: 0.7990 - val_loss: 0.0240 - val_accuracy: 0.6443\n",
            "Epoch 41/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.3329e-04 - accuracy: 0.8132 - val_loss: 0.0237 - val_accuracy: 0.6368\n",
            "Epoch 42/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 8.1896e-04 - accuracy: 0.8195 - val_loss: 0.0234 - val_accuracy: 0.6418\n",
            "Epoch 43/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.7951e-04 - accuracy: 0.8173 - val_loss: 0.0225 - val_accuracy: 0.6378\n",
            "Epoch 44/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.0134e-04 - accuracy: 0.8175 - val_loss: 0.0239 - val_accuracy: 0.6408\n",
            "Epoch 45/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 5.6522e-04 - accuracy: 0.8288 - val_loss: 0.0223 - val_accuracy: 0.6423\n",
            "Epoch 46/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.6727e-04 - accuracy: 0.8118 - val_loss: 0.0219 - val_accuracy: 0.6403\n",
            "Epoch 47/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.0038e-04 - accuracy: 0.8242 - val_loss: 0.0229 - val_accuracy: 0.6368\n",
            "Epoch 48/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 8.5177e-04 - accuracy: 0.8117 - val_loss: 0.0212 - val_accuracy: 0.6428\n",
            "Epoch 49/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.7813e-04 - accuracy: 0.8184 - val_loss: 0.0223 - val_accuracy: 0.6343\n",
            "Epoch 50/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.8879e-04 - accuracy: 0.8205 - val_loss: 0.0209 - val_accuracy: 0.6428\n",
            "Epoch 51/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.8163e-04 - accuracy: 0.8239 - val_loss: 0.0202 - val_accuracy: 0.6443\n",
            "Epoch 52/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.8357e-04 - accuracy: 0.8082 - val_loss: 0.0190 - val_accuracy: 0.6453\n",
            "Epoch 53/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.7564e-04 - accuracy: 0.8132 - val_loss: 0.0198 - val_accuracy: 0.6353\n",
            "Epoch 54/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.3751e-04 - accuracy: 0.8366 - val_loss: 0.0200 - val_accuracy: 0.6393\n",
            "Epoch 55/100\n",
            "134/134 [==============================] - 0s 3ms/step - loss: 7.8063e-04 - accuracy: 0.8098 - val_loss: 0.0196 - val_accuracy: 0.6428\n",
            "Epoch 56/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.5869e-04 - accuracy: 0.8255 - val_loss: 0.0198 - val_accuracy: 0.6408\n",
            "Epoch 57/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.5763e-04 - accuracy: 0.8209 - val_loss: 0.0197 - val_accuracy: 0.6438\n",
            "Epoch 58/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.8734e-04 - accuracy: 0.8338 - val_loss: 0.0196 - val_accuracy: 0.6388\n",
            "Epoch 59/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.6464e-04 - accuracy: 0.8374 - val_loss: 0.0204 - val_accuracy: 0.6433\n",
            "Epoch 60/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.6670e-04 - accuracy: 0.8404 - val_loss: 0.0192 - val_accuracy: 0.6363\n",
            "Epoch 61/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.5317e-04 - accuracy: 0.8165 - val_loss: 0.0195 - val_accuracy: 0.6403\n",
            "Epoch 62/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.9903e-04 - accuracy: 0.8210 - val_loss: 0.0194 - val_accuracy: 0.6333\n",
            "Epoch 63/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.4187e-04 - accuracy: 0.8272 - val_loss: 0.0188 - val_accuracy: 0.6373\n",
            "Epoch 64/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.2341e-04 - accuracy: 0.8289 - val_loss: 0.0185 - val_accuracy: 0.6368\n",
            "Epoch 65/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.3752e-04 - accuracy: 0.8363 - val_loss: 0.0180 - val_accuracy: 0.6383\n",
            "Epoch 66/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.9787e-04 - accuracy: 0.8175 - val_loss: 0.0183 - val_accuracy: 0.6428\n",
            "Epoch 67/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.7502e-04 - accuracy: 0.8161 - val_loss: 0.0181 - val_accuracy: 0.6368\n",
            "Epoch 68/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.7154e-04 - accuracy: 0.8205 - val_loss: 0.0192 - val_accuracy: 0.6428\n",
            "Epoch 69/100\n",
            "134/134 [==============================] - 0s 3ms/step - loss: 6.3062e-04 - accuracy: 0.8145 - val_loss: 0.0193 - val_accuracy: 0.6338\n",
            "Epoch 70/100\n",
            "134/134 [==============================] - 0s 4ms/step - loss: 7.1430e-04 - accuracy: 0.8077 - val_loss: 0.0183 - val_accuracy: 0.6373\n",
            "Epoch 71/100\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 7.3611e-04 - accuracy: 0.8027 - val_loss: 0.0175 - val_accuracy: 0.6473\n",
            "Epoch 72/100\n",
            "134/134 [==============================] - 0s 4ms/step - loss: 6.3812e-04 - accuracy: 0.8274 - val_loss: 0.0194 - val_accuracy: 0.6353\n",
            "Epoch 73/100\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 6.7954e-04 - accuracy: 0.8249 - val_loss: 0.0180 - val_accuracy: 0.6353\n",
            "Epoch 74/100\n",
            "134/134 [==============================] - 0s 4ms/step - loss: 7.3776e-04 - accuracy: 0.8292 - val_loss: 0.0171 - val_accuracy: 0.6438\n",
            "Epoch 75/100\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 6.4539e-04 - accuracy: 0.8261 - val_loss: 0.0171 - val_accuracy: 0.6423\n",
            "Epoch 76/100\n",
            "134/134 [==============================] - 0s 3ms/step - loss: 6.3422e-04 - accuracy: 0.8060 - val_loss: 0.0169 - val_accuracy: 0.6493\n",
            "Epoch 77/100\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 6.2291e-04 - accuracy: 0.8142 - val_loss: 0.0167 - val_accuracy: 0.6473\n",
            "Epoch 78/100\n",
            "134/134 [==============================] - 0s 3ms/step - loss: 7.4168e-04 - accuracy: 0.8088 - val_loss: 0.0171 - val_accuracy: 0.6418\n",
            "Epoch 79/100\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 7.0133e-04 - accuracy: 0.8224 - val_loss: 0.0167 - val_accuracy: 0.6478\n",
            "Epoch 80/100\n",
            "134/134 [==============================] - 0s 4ms/step - loss: 7.7206e-04 - accuracy: 0.8182 - val_loss: 0.0171 - val_accuracy: 0.6473\n",
            "Epoch 81/100\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 6.4199e-04 - accuracy: 0.8157 - val_loss: 0.0166 - val_accuracy: 0.6483\n",
            "Epoch 82/100\n",
            "134/134 [==============================] - 0s 4ms/step - loss: 8.3171e-04 - accuracy: 0.8264 - val_loss: 0.0163 - val_accuracy: 0.6538\n",
            "Epoch 83/100\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 7.5594e-04 - accuracy: 0.8268 - val_loss: 0.0166 - val_accuracy: 0.6228\n",
            "Epoch 84/100\n",
            "134/134 [==============================] - 0s 4ms/step - loss: 7.0837e-04 - accuracy: 0.8290 - val_loss: 0.0170 - val_accuracy: 0.6648\n",
            "Epoch 85/100\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 7.6356e-04 - accuracy: 0.8264 - val_loss: 0.0167 - val_accuracy: 0.6608\n",
            "Epoch 86/100\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 6.5775e-04 - accuracy: 0.8241 - val_loss: 0.0167 - val_accuracy: 0.6668\n",
            "Epoch 87/100\n",
            "134/134 [==============================] - 0s 4ms/step - loss: 6.5010e-04 - accuracy: 0.8311 - val_loss: 0.0164 - val_accuracy: 0.6538\n",
            "Epoch 88/100\n",
            "134/134 [==============================] - 0s 4ms/step - loss: 9.2004e-04 - accuracy: 0.8012 - val_loss: 0.0165 - val_accuracy: 0.6858\n",
            "Epoch 89/100\n",
            "134/134 [==============================] - 1s 4ms/step - loss: 6.9934e-04 - accuracy: 0.8240 - val_loss: 0.0161 - val_accuracy: 0.6773\n",
            "Epoch 90/100\n",
            "134/134 [==============================] - 0s 4ms/step - loss: 7.0591e-04 - accuracy: 0.8186 - val_loss: 0.0160 - val_accuracy: 0.6768\n",
            "Epoch 91/100\n",
            "134/134 [==============================] - 0s 3ms/step - loss: 7.1930e-04 - accuracy: 0.8254 - val_loss: 0.0163 - val_accuracy: 0.6608\n",
            "Epoch 92/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 5.6557e-04 - accuracy: 0.8154 - val_loss: 0.0163 - val_accuracy: 0.6973\n",
            "Epoch 93/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.7248e-04 - accuracy: 0.8151 - val_loss: 0.0166 - val_accuracy: 0.6573\n",
            "Epoch 94/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 8.2890e-04 - accuracy: 0.8140 - val_loss: 0.0163 - val_accuracy: 0.6793\n",
            "Epoch 95/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 6.5746e-04 - accuracy: 0.8191 - val_loss: 0.0156 - val_accuracy: 0.6718\n",
            "Epoch 96/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.7837e-04 - accuracy: 0.8231 - val_loss: 0.0161 - val_accuracy: 0.6868\n",
            "Epoch 97/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 8.3521e-04 - accuracy: 0.8081 - val_loss: 0.0157 - val_accuracy: 0.6873\n",
            "Epoch 98/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.4965e-04 - accuracy: 0.8212 - val_loss: 0.0161 - val_accuracy: 0.6898\n",
            "Epoch 99/100\n",
            "134/134 [==============================] - 0s 3ms/step - loss: 7.3873e-04 - accuracy: 0.8234 - val_loss: 0.0156 - val_accuracy: 0.6813\n",
            "Epoch 100/100\n",
            "134/134 [==============================] - 0s 2ms/step - loss: 7.1301e-04 - accuracy: 0.8168 - val_loss: 0.0155 - val_accuracy: 0.6848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwnafL9UA14S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}