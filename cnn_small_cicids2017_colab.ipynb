{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "cnn_small_cicids2017_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwangliberty/AIoTDesign-Frontend/blob/master/cnn_small_cicids2017_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HakdgCXBymAw"
      },
      "source": [
        "# Intrusion Detection by using small CICIDS 2017 DataSet with 4000 examples each type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqdB1_F0ymAz"
      },
      "source": [
        "import os\n",
        "from os.path import join\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7LnjNAcvll6"
      },
      "source": [
        "def make_value2index(attacks):\r\n",
        "    #make dictionary\r\n",
        "    attacks = sorted(attacks)\r\n",
        "    d = {}\r\n",
        "    counter=0\r\n",
        "    for attack in attacks:\r\n",
        "        d[attack] = counter\r\n",
        "        counter+=1\r\n",
        "    return d"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bJxEKODvmH5"
      },
      "source": [
        "# chganges label from string to integer/index\r\n",
        "def encode_label(Y_str):\r\n",
        "    labels_d = make_value2index(np.unique(Y_str))\r\n",
        "    Y = [labels_d[y_str] for y_str  in Y_str]\r\n",
        "    Y = np.array(Y)\r\n",
        "    return np.array(Y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW4i5wbIrCfT"
      },
      "source": [
        "def get_dataframe_ofType(df, traffic_type):\r\n",
        "    \"\"\"\r\n",
        "    Analyze traffic distribution of pandas data frame containing IDS2017 CSV\r\n",
        "    file with labelled traffic\r\n",
        "\r\n",
        "    Parameter\r\n",
        "    ---------\r\n",
        "    df: DataFrame\r\n",
        "        Pandas DataFrame corresponding to the content of a CSV file\r\n",
        "    traffic_type: string\r\n",
        "        name corresponding to traffic type\r\n",
        "\r\n",
        "    Return\r\n",
        "    ------\r\n",
        "    req_df: DataFrame\r\n",
        "        Pandas DataFrame containing only the requested traffic type\r\n",
        "    \"\"\"\r\n",
        "    req_df = df.loc[df['Label'] == traffic_type]\r\n",
        "    # don't keep original indexes\r\n",
        "    #req_df = req_df.reset_index()\r\n",
        "    return req_df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crMkU4GxphLu"
      },
      "source": [
        "def get_typelist(df):\r\n",
        "    \"\"\"\r\n",
        "    Extract traffic type from a pandas data frame containing IDS2017 CSV\r\n",
        "    file with labelled traffic\r\n",
        "\r\n",
        "    Parameter\r\n",
        "    ---------\r\n",
        "    df: DataFrame\r\n",
        "        Pandas DataFrame corresponding to the content of a CSV file\r\n",
        "\r\n",
        "    Return\r\n",
        "    ------\r\n",
        "    traffic_type_list: list\r\n",
        "        List of traffic types contained in the DataFrame\r\n",
        "    \"\"\"\r\n",
        "    traffic_type_list = df['Label'].value_counts().index.tolist()\r\n",
        "    return traffic_type_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyxQXnv_uJok"
      },
      "source": [
        "#We balance data as follows:\r\n",
        "#1) oversample small classes so that their population/count is equal to mean_number_of_samples_per_class\r\n",
        "#2) undersample large classes so that their count is equal to mean_number_of_samples_per_class\r\n",
        "def balance_data(X,y,seed, mean_samples):\r\n",
        "    np.random.seed(seed)\r\n",
        "    unique,counts = np.unique(y,return_counts=True)\r\n",
        "    mean_samples_per_class = mean_samples # int(round(np.mean(counts)))\r\n",
        "    N,D = X.shape #(number of examples, number of features)\r\n",
        "    new_X = np.empty((0,D)) \r\n",
        "    new_y = np.empty((0),dtype=int)\r\n",
        "    for i,c in enumerate(unique):\r\n",
        "        temp_x = X[y==c]\r\n",
        "        indices = np.random.choice(temp_x.shape[0],mean_samples_per_class) # gets `mean_samples_per_class` indices of class `c`\r\n",
        "        new_X = np.concatenate((new_X,temp_x[indices]),axis=0) # now we put new data into new_X \r\n",
        "        temp_y = np.ones(mean_samples_per_class,dtype=int)*c\r\n",
        "        new_y = np.concatenate((new_y,temp_y),axis=0)\r\n",
        "        \r\n",
        "    # in order to break class order in data we need shuffling\r\n",
        "    indices = np.arange(new_y.shape[0])\r\n",
        "    np.random.shuffle(indices)\r\n",
        "    new_X =  new_X[indices,:]\r\n",
        "    new_y = new_y[indices]\r\n",
        "    return (new_X,new_y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-kNtwdKymAz"
      },
      "source": [
        "## Step 1. Read cleaned CICIDS2017 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is2az0Giy0iC"
      },
      "source": [
        "Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9zJ-0oQy1Gy",
        "outputId": "c62c62a6-4b23-43bb-c17d-41911540222b"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aL5u5kynL_B"
      },
      "source": [
        "# All columns\r\n",
        "col_names = np.array(['Source Port', 'Destination Port',\r\n",
        "                      'Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets',\r\n",
        "                      'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\r\n",
        "                      'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std',\r\n",
        "                      'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total',\r\n",
        "                      'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\r\n",
        "                      'Bwd IAT Min', 'Fwd PSH Flags', 'Fwd URG Flags', 'Fwd Header Length', 'Bwd Header Length',\r\n",
        "                      'Fwd Packets/s', 'Bwd Packets/s', 'Min Packet Length', 'Max Packet Length', 'Packet Length Mean', 'Packet Length Std',\r\n",
        "                      'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\r\n",
        "                      'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size',\r\n",
        "                      'Avg Bwd Segment Size','Subflow Fwd Packets', 'Subflow Fwd Bytes',\r\n",
        "                      'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward', 'Init_Win_bytes_backward',\r\n",
        "                      'act_data_pkt_fwd', 'min_seg_size_forward', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\r\n",
        "                      'Idle Std', 'Idle Max', 'Idle Min', 'Label'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC6XqERIc9c4"
      },
      "source": [
        "According to \"**Selection and Performance Analysis of CICIDS2017 Features Importance**\", the important features are: *Destination Port, Fwd IAT Min, Init_Win_bytes_Forward, Init_Win_bytes_backward* and *FlowIATMin*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSfAZhiPCwpu"
      },
      "source": [
        "col_important = np.array(['Source Port', 'Destination Port', 'Fwd IAT Min', 'Init_Win_bytes_forward', 'Init_Win_bytes_backward', 'Flow IAT Min',\r\n",
        "                      'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets',\r\n",
        "                      'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Protocol', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\r\n",
        "                      'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std',\r\n",
        "                      'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Fwd IAT Total',\r\n",
        "                      'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\r\n",
        "                      'Bwd IAT Min', 'Fwd PSH Flags', 'Fwd URG Flags', 'Fwd Header Length', 'Bwd Header Length',\r\n",
        "                      'Fwd Packets/s', 'Bwd Packets/s', 'Min Packet Length', 'Max Packet Length', 'Packet Length Mean', 'Packet Length Std',\r\n",
        "                      'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\r\n",
        "                      'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size',\r\n",
        "                      'Avg Bwd Segment Size','Subflow Fwd Packets', 'Subflow Fwd Bytes',\r\n",
        "                      'Subflow Bwd Packets', 'Subflow Bwd Bytes', \r\n",
        "                      'act_data_pkt_fwd', 'min_seg_size_forward', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\r\n",
        "                      'Idle Std', 'Idle Max', 'Idle Min', 'Label'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E17GpxaNymAz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "f4f755cb-c555-41d9-991c-92d62b0b39b5"
      },
      "source": [
        "# load train data\n",
        "df_train = pd.read_csv('/content/drive/My Drive/CICIDS2017/train_set.csv',names=col_names, skiprows=1)  \n",
        "#df_train = pd.read_csv('/content/drive/My Drive/CICIDS2017/train_set.csv',names=col_important, skiprows=1) \n",
        "df_train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5141</th>\n",
              "      <th>172.16.0.1-192.168.10.50-50294-80-6</th>\n",
              "      <th>172.16.0.1</th>\n",
              "      <th>50294.0</th>\n",
              "      <th>192.168.10.50</th>\n",
              "      <th>80.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>5/7/2017 10:33</th>\n",
              "      <th>63101744.0</th>\n",
              "      <th>7.0</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.110932</td>\n",
              "      <td>10500000.0</td>\n",
              "      <td>1.190000e+07</td>\n",
              "      <td>32100000.0</td>\n",
              "      <td>998158.0</td>\n",
              "      <td>63100000.0</td>\n",
              "      <td>1.050000e+07</td>\n",
              "      <td>1.190000e+07</td>\n",
              "      <td>32100000.0</td>\n",
              "      <td>998158.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.110932</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29200.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>7006133.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7006133.0</td>\n",
              "      <td>7006133.0</td>\n",
              "      <td>18700000.0</td>\n",
              "      <td>12200000.0</td>\n",
              "      <td>32100000.0</td>\n",
              "      <td>8015895.0</td>\n",
              "      <td>DoS Slowhttptest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40963</th>\n",
              "      <th>172.16.0.1-192.168.10.50-37796-1199-6</th>\n",
              "      <th>172.16.0.1</th>\n",
              "      <th>37796.0</th>\n",
              "      <th>192.168.10.50</th>\n",
              "      <th>1199.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>7/7/2017 2:52</th>\n",
              "      <th>62.0</th>\n",
              "      <th>1.0</th>\n",
              "      <th>1.0</th>\n",
              "      <th>2.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>2.0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.290323e+05</td>\n",
              "      <td>32258.064520</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16129.032260</td>\n",
              "      <td>16129.032260</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.309401</td>\n",
              "      <td>5.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PortScan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27718</th>\n",
              "      <th>172.217.6.200-192.168.10.12-443-42634-6</th>\n",
              "      <th>172.217.6.200</th>\n",
              "      <th>443.0</th>\n",
              "      <th>192.168.10.12</th>\n",
              "      <th>42634.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>03/07/2017 09:49:12</th>\n",
              "      <th>3.0</th>\n",
              "      <th>2.0</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>666666.666667</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>666666.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>357.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106492</th>\n",
              "      <th>192.168.10.8-23.208.79.206-52235-443-6</th>\n",
              "      <th>192.168.10.8</th>\n",
              "      <th>52235.0</th>\n",
              "      <th>23.208.79.206</th>\n",
              "      <th>443.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>4/7/2017 11:46</th>\n",
              "      <th>5007496.0</th>\n",
              "      <th>7.0</th>\n",
              "      <th>4.0</th>\n",
              "      <th>1679.0</th>\n",
              "      <th>152.0</th>\n",
              "      <th>1080.0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>239.857143</td>\n",
              "      <td>415.237052</td>\n",
              "      <td>152.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>3.656518e+02</td>\n",
              "      <td>2.196707</td>\n",
              "      <td>500749.6</td>\n",
              "      <td>1.543257e+06</td>\n",
              "      <td>4892570.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5007496.0</td>\n",
              "      <td>8.345827e+05</td>\n",
              "      <td>2.018795e+06</td>\n",
              "      <td>4955369.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>87090.0</td>\n",
              "      <td>29030.0</td>\n",
              "      <td>31709.63089</td>\n",
              "      <td>63179.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>1.397904</td>\n",
              "      <td>0.798802</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>152.583333</td>\n",
              "      <td>327.660428</td>\n",
              "      <td>107361.356100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>166.454545</td>\n",
              "      <td>239.857143</td>\n",
              "      <td>38.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1679.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>8192.0</td>\n",
              "      <td>946.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63559</th>\n",
              "      <th>192.168.10.14-52.84.30.203-59835-80-6</th>\n",
              "      <th>52.84.30.203</th>\n",
              "      <th>80.0</th>\n",
              "      <th>192.168.10.14</th>\n",
              "      <th>59835.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>6/7/2017 10:04</th>\n",
              "      <th>4.0</th>\n",
              "      <th>1.0</th>\n",
              "      <th>1.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>6.0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>500000.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>256.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                           Source Port  ...             Label\n",
              "5141   172.16.0.1-192.168.10.50-50294-80-6     172.16.0.1    50294.0 192.168.10.50 80.0    6.0 5/7/2017 10:33      63101744.0 7.0 0.0 0.0    0.0   0.0             0.0  ...  DoS Slowhttptest\n",
              "40963  172.16.0.1-192.168.10.50-37796-1199-6   172.16.0.1    37796.0 192.168.10.50 1199.0  6.0 7/7/2017 2:52       62.0       1.0 1.0 2.0    6.0   2.0             2.0  ...          PortScan\n",
              "27718  172.217.6.200-192.168.10.12-443-42634-6 172.217.6.200 443.0   192.168.10.12 42634.0 6.0 03/07/2017 09:49:12 3.0        2.0 0.0 0.0    0.0   0.0             0.0  ...            BENIGN\n",
              "106492 192.168.10.8-23.208.79.206-52235-443-6  192.168.10.8  52235.0 23.208.79.206 443.0   6.0 4/7/2017 11:46      5007496.0  7.0 4.0 1679.0 152.0 1080.0          0.0  ...            BENIGN\n",
              "63559  192.168.10.14-52.84.30.203-59835-80-6   52.84.30.203  80.0    192.168.10.14 59835.0 6.0 6/7/2017 10:04      4.0        1.0 1.0 6.0    6.0   6.0             6.0  ...            BENIGN\n",
              "\n",
              "[5 rows x 72 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXMkWoEUymA0",
        "outputId": "ac9f873d-2d71-4af9-a84a-4f8d1c6dd4c9"
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/My Drive/CICIDS2017/test_set.csv',names=col_names, skiprows=1)  \n",
        "#df_test = pd.read_csv('/content/drive/My Drive/CICIDS2017/test_set.csv',names=col_important, skiprows=1) \n",
        "print('Test set size: ', df_test.shape)\n",
        "\n",
        "df_val = pd.read_csv('/content/drive/My Drive/CICIDS2017/crossval_set.csv',names=col_names, skiprows=1)  \n",
        "#df_val = pd.read_csv('/content/drive/My Drive/CICIDS2017/crossval_set.csv',names=col_important, skiprows=1) \n",
        "print('Validation set size: ', df_val.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set size:  (278270, 72)\n",
            "Validation set size:  (278270, 72)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPLtWtJ8ymA1",
        "outputId": "646204cc-fc07-4be9-fd25-fdb2e48e5d89"
      },
      "source": [
        "# Here we can see the number of rows and columns for each table.\n",
        "print(df_train.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(556548, 72)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVGdQOpFnhMT"
      },
      "source": [
        "Count the number of attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK5kP4X3ngMA",
        "outputId": "80e3233f-11de-4d35-aeae-4a6242fe496e"
      },
      "source": [
        "df_train['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        278274\n",
              "DoS Hulk                      115062\n",
              "PortScan                       79402\n",
              "DDoS                           64012\n",
              "DoS GoldenEye                   5146\n",
              "FTP-Patator                     3967\n",
              "SSH-Patator                     2948\n",
              "DoS slowloris                   2898\n",
              "DoS Slowhttptest                2749\n",
              "Bot                              978\n",
              "Web Attack  Brute Force         753\n",
              "Web Attack  XSS                 326\n",
              "Infiltration                      18\n",
              "Web Attack  Sql Injection        10\n",
              "Heartbleed                         5\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCjcgUmlnr0T",
        "outputId": "6abe84b1-9ea7-4705-eb3f-36a09236cb20"
      },
      "source": [
        "print('Test set: ')\r\n",
        "df_test['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        139135\n",
              "DoS Hulk                       57531\n",
              "PortScan                       39701\n",
              "DDoS                           32006\n",
              "DoS GoldenEye                   2573\n",
              "FTP-Patator                     1983\n",
              "SSH-Patator                     1474\n",
              "DoS slowloris                   1449\n",
              "DoS Slowhttptest                1374\n",
              "Bot                              489\n",
              "Web Attack  Brute Force         376\n",
              "Web Attack  XSS                 163\n",
              "Infiltration                       9\n",
              "Web Attack  Sql Injection         5\n",
              "Heartbleed                         2\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sIo9YzUnuY5",
        "outputId": "a0e4c697-ce43-4f85-d253-2bdb3fa87d2f"
      },
      "source": [
        "print('Validation set: ')\r\n",
        "df_val['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation set: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        139135\n",
              "DoS Hulk                       57531\n",
              "PortScan                       39701\n",
              "DDoS                           32006\n",
              "DoS GoldenEye                   2573\n",
              "FTP-Patator                     1983\n",
              "SSH-Patator                     1474\n",
              "DoS slowloris                   1449\n",
              "DoS Slowhttptest                1374\n",
              "Bot                              489\n",
              "Web Attack  Brute Force         376\n",
              "Web Attack  XSS                 163\n",
              "Infiltration                       9\n",
              "Web Attack  Sql Injection         5\n",
              "Heartbleed                         2\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzHvvoMDotTj"
      },
      "source": [
        "## Step 2. Randomly Selecting 2000 examples from each type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asjXEVY7yrXa"
      },
      "source": [
        "First, selecting 4000 examples for each type in train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW88xIvao0GO"
      },
      "source": [
        "df_label = df_train['Label']\r\n",
        "data = df_train.drop(columns=['Label'])\r\n",
        "X = data.values\r\n",
        "y = encode_label(df_label.values)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m32yYQ-prx45",
        "outputId": "656c4f8c-1cd9-400e-bd1c-92e9399c4668"
      },
      "source": [
        "print(X.shape)\r\n",
        "print(y.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(556548, 71)\n",
            "(556548,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo9psJWmx7y7",
        "outputId": "353ccef5-50ee-4b81-f445-1d3c724f907b"
      },
      "source": [
        "unique, counts = np.unique(y, return_counts=True)\r\n",
        "print(unique, counts)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] [278274    978  64012   5146 115062   2749   2898   3967      5     18\n",
            "  79402   2948    753     10    326]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDTCXiY-qtFZ"
      },
      "source": [
        "SEED = 2\r\n",
        "X_train,y_train = balance_data(X,y,seed=SEED, mean_samples=4000)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks1hpGiFyRi_",
        "outputId": "30a0091d-2a73-4240-e02d-0f08dc3daa96"
      },
      "source": [
        "print(X_train.shape)\r\n",
        "print(y_train.shape)\r\n",
        "unique, counts = np.unique(y_train, return_counts=True)\r\n",
        "print(unique, counts)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 71)\n",
            "(60000,)\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] [4000 4000 4000 4000 4000 4000 4000 4000 4000 4000 4000 4000 4000 4000\n",
            " 4000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gua98tTqypEx"
      },
      "source": [
        "Next, selecting 1000 examples from validation datesets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DbW1x3UzCzT"
      },
      "source": [
        "df_label = df_test['Label']\r\n",
        "data = df_test.drop(columns=['Label'])\r\n",
        "X = data.values\r\n",
        "y = encode_label(df_label.values)\r\n",
        "\r\n",
        "SEED = 2\r\n",
        "X_test,y_test = balance_data(X,y,seed=SEED, mean_samples=1000)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLLES1n7zjAC"
      },
      "source": [
        "Next, selecting 500 examples from test datesets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7VxrFq3zQ8M"
      },
      "source": [
        "df_label = df_val['Label']\r\n",
        "data = df_val.drop(columns=['Label'])\r\n",
        "X = data.values\r\n",
        "y = encode_label(df_label.values)\r\n",
        "\r\n",
        "SEED = 2\r\n",
        "X_val,y_val = balance_data(X,y,seed=SEED, mean_samples=500)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtjNVDHfymA1"
      },
      "source": [
        "## Step 3. Normalization\n",
        "\n",
        "The continuous feature values are normalized into the same feature space. This is important when using features that have different measurements, and is a general requirement of many machine learning algorithms. Therefore, the values for this dataset are also normalized using the Min-Max scaling technique, bringing them all within a range of [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTfYdWHymA2"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5JH_i4EymA2",
        "outputId": "ab4d1032-7ec3-4306-8ded-c9797e91cab2"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_train"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.00109412, 0.00130398, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.0077991 , 0.0197178 , ..., 0.        , 0.05733978,\n",
              "        0.05733978]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PuA6ri3ymA2",
        "outputId": "8f5570f7-b51c-429b-82f0-9598d7197440"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 71)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry0R9AFFymA3"
      },
      "source": [
        "X_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeFIseICymA3",
        "outputId": "586fec04-00f3-46e7-9594-52cda19e2075"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000, 71)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1mN1ZAI0gcL",
        "outputId": "03fd1268-87e6-4f44-eead-6fb22f2818ba"
      },
      "source": [
        "X_val = scaler.fit_transform(X_val)\r\n",
        "X_val"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.00095839, 0.02132314, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.00100857, 0.00039029, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.01865954, 0.0270547 , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.00302572, 0.00117087, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.02337832, 0.05175073, ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGN8Mww10uvV"
      },
      "source": [
        "## Step 4. One-hot encoding for labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XayluHqdymA3"
      },
      "source": [
        "y_train and y_test have to be one-hot-encoded. That means they must have dimension (number_of_samples, 15), where 15 denotes number of classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pMxFRGCymA4"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na5t3wpmymA4",
        "outputId": "68484b1c-358c-4fe5-83cc-b12ccd58243b"
      },
      "source": [
        "y_train_v = to_categorical(y_train, 15)\n",
        "y_test_v = to_categorical(y_test, 15)\n",
        "y_val_v = to_categorical(y_val, 15)\n",
        "print(y_train_v.shape)\n",
        "print(y_test_v.shape)\n",
        "print(y_val_v.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 15)\n",
            "(15000, 15)\n",
            "(7500, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79Q2ezxEymA6"
      },
      "source": [
        "## Step 5. Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYdmYYyWymA6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Flatten, Dense, Activation,Dropout\n",
        "from tensorflow.keras.constraints import max_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VinchNXyymA7",
        "outputId": "e8330276-212e-423a-a83c-2acca4851fbf"
      },
      "source": [
        "#hyper-params\n",
        "batch_size = 100 # increasing batch size with more gpu added\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "num_class = 15                   # 15 intrusion classes, including benign traffic class\n",
        "num_epochs = 90\n",
        "\n",
        "print(input_dim)\n",
        "print(num_class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SeAQGIoymA8",
        "outputId": "606356e3-a50a-4066-c2e4-f646da8aab90"
      },
      "source": [
        "X_train_r = np.zeros((len(X_train), input_dim, 1))\n",
        "X_train_r[:, :, 0] = X_train[:, :input_dim]\n",
        "print(X_train_r.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 71, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlcgM-4311Ee",
        "outputId": "060993ac-8d09-4413-c430-6eb1a79268e9"
      },
      "source": [
        "X_val_r = np.zeros((len(X_val), input_dim, 1))\r\n",
        "X_val_r[:, :, 0] = X_val[:, :input_dim]\r\n",
        "print(X_val_r.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7500, 71, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B96MRlI_ymA8",
        "outputId": "4ee1bc49-72af-4fd8-ef47-bc57d03306ef"
      },
      "source": [
        "X_test_r = np.zeros((len(X_test), input_dim, 1))\n",
        "X_test_r[:, :, 0] = X_test[:, :input_dim]\n",
        "print(X_test_r.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15000, 71, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKMiVwhCXx2I"
      },
      "source": [
        "**Model with 2 Con1D layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJqaGS9SX01m",
        "outputId": "ab5a98dd-ff10-4fef-c48e-9b05f971be0f"
      },
      "source": [
        "model2 = Sequential()\r\n",
        "\r\n",
        "# input layer\r\n",
        "model2.add(Conv1D(filters=60, kernel_size=11,  input_shape=(71,1)))\r\n",
        "#model2.add(BatchNormalization(axis=1))\r\n",
        "model2.add(Activation('relu'))\r\n",
        "model2.add(Dropout(0.1))\r\n",
        "\r\n",
        "model2.add(Conv1D(filters=60, kernel_size=3))\r\n",
        "#model2.add(BatchNormalization(axis=1))\r\n",
        "model2.add(Activation('relu'))\r\n",
        "model2.add(Dropout(0.1))\r\n",
        "\r\n",
        "model2.add(Conv1D(filters=60, kernel_size=7))\r\n",
        "#model2.add(BatchNormalization(axis=1))\r\n",
        "model2.add(Activation('relu'))\r\n",
        "model2.add(Dropout(0.1))\r\n",
        "\r\n",
        "model2.add(Flatten())\r\n",
        "#model2.add(Dropout(0.1))\r\n",
        "model2.add(Dense(128, activation='relu'))\r\n",
        "model2.add(Dense(num_class))\r\n",
        "model2.add(Activation('softmax'))\r\n",
        "\r\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 61, 60)            720       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 61, 60)            0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 61, 60)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 59, 60)            10860     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 59, 60)            0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 59, 60)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 53, 60)            25260     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 53, 60)            0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 53, 60)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3180)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               407168    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 15)                1935      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 445,943\n",
            "Trainable params: 445,943\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u3i2MkUYNo3"
      },
      "source": [
        "learning_rates = 1e-3\r\n",
        "optim = tf.keras.optimizers.Adam(lr=learning_rates, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\r\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NGP29aXYPyw",
        "outputId": "7858f36e-9314-4174-d5a5-5d194f312ddc"
      },
      "source": [
        "model2.fit(X_train_r, y_train_v, epochs=100, batch_size=batch_size, validation_data=(X_val_r, y_val_v), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "600/600 [==============================] - 10s 4ms/step - loss: 0.9566 - accuracy: 0.6844 - val_loss: 0.3925 - val_accuracy: 0.8560\n",
            "Epoch 2/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2993 - accuracy: 0.8746 - val_loss: 0.3710 - val_accuracy: 0.8488\n",
            "Epoch 3/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2609 - accuracy: 0.8799 - val_loss: 0.3645 - val_accuracy: 0.8527\n",
            "Epoch 4/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2427 - accuracy: 0.8864 - val_loss: 0.3273 - val_accuracy: 0.8615\n",
            "Epoch 5/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2304 - accuracy: 0.8865 - val_loss: 0.3215 - val_accuracy: 0.8669\n",
            "Epoch 6/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2244 - accuracy: 0.8906 - val_loss: 0.3465 - val_accuracy: 0.8791\n",
            "Epoch 7/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2147 - accuracy: 0.8942 - val_loss: 0.3312 - val_accuracy: 0.8579\n",
            "Epoch 8/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2043 - accuracy: 0.8978 - val_loss: 0.3430 - val_accuracy: 0.8565\n",
            "Epoch 9/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1987 - accuracy: 0.9003 - val_loss: 0.3313 - val_accuracy: 0.8781\n",
            "Epoch 10/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1930 - accuracy: 0.8967 - val_loss: 0.3100 - val_accuracy: 0.8604\n",
            "Epoch 11/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1920 - accuracy: 0.9000 - val_loss: 0.3725 - val_accuracy: 0.8601\n",
            "Epoch 12/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1903 - accuracy: 0.9000 - val_loss: 0.3704 - val_accuracy: 0.8720\n",
            "Epoch 13/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1905 - accuracy: 0.8999 - val_loss: 0.4024 - val_accuracy: 0.8699\n",
            "Epoch 14/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1847 - accuracy: 0.9021 - val_loss: 0.4170 - val_accuracy: 0.8625\n",
            "Epoch 15/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1838 - accuracy: 0.9015 - val_loss: 0.3662 - val_accuracy: 0.8812\n",
            "Epoch 16/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1839 - accuracy: 0.9002 - val_loss: 0.4223 - val_accuracy: 0.8795\n",
            "Epoch 17/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1817 - accuracy: 0.9038 - val_loss: 0.4045 - val_accuracy: 0.8701\n",
            "Epoch 18/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1811 - accuracy: 0.9023 - val_loss: 0.3927 - val_accuracy: 0.8700\n",
            "Epoch 19/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1750 - accuracy: 0.9066 - val_loss: 0.4338 - val_accuracy: 0.8735\n",
            "Epoch 20/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1746 - accuracy: 0.9065 - val_loss: 0.4291 - val_accuracy: 0.8703\n",
            "Epoch 21/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1765 - accuracy: 0.9055 - val_loss: 0.3819 - val_accuracy: 0.8777\n",
            "Epoch 22/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1726 - accuracy: 0.9073 - val_loss: 0.4700 - val_accuracy: 0.8805\n",
            "Epoch 23/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1755 - accuracy: 0.9048 - val_loss: 0.4620 - val_accuracy: 0.8707\n",
            "Epoch 24/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1750 - accuracy: 0.9054 - val_loss: 0.4337 - val_accuracy: 0.8624\n",
            "Epoch 25/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1701 - accuracy: 0.9105 - val_loss: 0.3926 - val_accuracy: 0.8735\n",
            "Epoch 26/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1738 - accuracy: 0.9076 - val_loss: 0.4228 - val_accuracy: 0.8725\n",
            "Epoch 27/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1717 - accuracy: 0.9074 - val_loss: 0.4564 - val_accuracy: 0.8640\n",
            "Epoch 28/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1694 - accuracy: 0.9134 - val_loss: 0.3712 - val_accuracy: 0.8739\n",
            "Epoch 29/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1698 - accuracy: 0.9072 - val_loss: 0.4643 - val_accuracy: 0.8747\n",
            "Epoch 30/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1666 - accuracy: 0.9122 - val_loss: 0.4803 - val_accuracy: 0.8683\n",
            "Epoch 31/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1630 - accuracy: 0.9126 - val_loss: 0.4179 - val_accuracy: 0.8637\n",
            "Epoch 32/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1671 - accuracy: 0.9130 - val_loss: 0.5520 - val_accuracy: 0.8731\n",
            "Epoch 33/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1636 - accuracy: 0.9141 - val_loss: 0.4773 - val_accuracy: 0.8797\n",
            "Epoch 34/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1636 - accuracy: 0.9145 - val_loss: 0.5031 - val_accuracy: 0.8589\n",
            "Epoch 35/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1608 - accuracy: 0.9140 - val_loss: 0.4917 - val_accuracy: 0.8741\n",
            "Epoch 36/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1608 - accuracy: 0.9153 - val_loss: 0.5210 - val_accuracy: 0.8736\n",
            "Epoch 37/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1608 - accuracy: 0.9165 - val_loss: 0.4987 - val_accuracy: 0.8871\n",
            "Epoch 38/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1565 - accuracy: 0.9151 - val_loss: 0.4952 - val_accuracy: 0.8828\n",
            "Epoch 39/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1592 - accuracy: 0.9159 - val_loss: 0.4449 - val_accuracy: 0.8729\n",
            "Epoch 40/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1573 - accuracy: 0.9168 - val_loss: 0.4256 - val_accuracy: 0.8848\n",
            "Epoch 41/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1491 - accuracy: 0.9210 - val_loss: 0.4525 - val_accuracy: 0.8852\n",
            "Epoch 42/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1525 - accuracy: 0.9169 - val_loss: 0.4501 - val_accuracy: 0.8833\n",
            "Epoch 43/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1501 - accuracy: 0.9194 - val_loss: 0.4541 - val_accuracy: 0.8916\n",
            "Epoch 44/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1468 - accuracy: 0.9207 - val_loss: 0.4526 - val_accuracy: 0.8820\n",
            "Epoch 45/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1502 - accuracy: 0.9206 - val_loss: 0.4726 - val_accuracy: 0.8760\n",
            "Epoch 46/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1485 - accuracy: 0.9214 - val_loss: 0.5251 - val_accuracy: 0.8800\n",
            "Epoch 47/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1459 - accuracy: 0.9205 - val_loss: 0.5104 - val_accuracy: 0.8823\n",
            "Epoch 48/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1453 - accuracy: 0.9221 - val_loss: 0.4918 - val_accuracy: 0.8668\n",
            "Epoch 49/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1447 - accuracy: 0.9203 - val_loss: 0.4660 - val_accuracy: 0.8796\n",
            "Epoch 50/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1425 - accuracy: 0.9239 - val_loss: 0.4907 - val_accuracy: 0.8728\n",
            "Epoch 51/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1502 - accuracy: 0.9204 - val_loss: 0.4611 - val_accuracy: 0.8773\n",
            "Epoch 52/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1415 - accuracy: 0.9230 - val_loss: 0.5041 - val_accuracy: 0.8799\n",
            "Epoch 53/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1422 - accuracy: 0.9259 - val_loss: 0.4665 - val_accuracy: 0.8783\n",
            "Epoch 54/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1409 - accuracy: 0.9248 - val_loss: 0.4802 - val_accuracy: 0.8780\n",
            "Epoch 55/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1349 - accuracy: 0.9261 - val_loss: 0.5225 - val_accuracy: 0.8785\n",
            "Epoch 56/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1356 - accuracy: 0.9263 - val_loss: 0.4566 - val_accuracy: 0.9007\n",
            "Epoch 57/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1345 - accuracy: 0.9277 - val_loss: 0.4714 - val_accuracy: 0.8768\n",
            "Epoch 58/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1364 - accuracy: 0.9288 - val_loss: 0.4861 - val_accuracy: 0.9071\n",
            "Epoch 59/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1342 - accuracy: 0.9284 - val_loss: 0.4777 - val_accuracy: 0.8799\n",
            "Epoch 60/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1342 - accuracy: 0.9283 - val_loss: 0.4863 - val_accuracy: 0.8832\n",
            "Epoch 61/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1358 - accuracy: 0.9246 - val_loss: 0.4600 - val_accuracy: 0.8780\n",
            "Epoch 62/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1367 - accuracy: 0.9267 - val_loss: 0.4577 - val_accuracy: 0.8783\n",
            "Epoch 63/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1393 - accuracy: 0.9255 - val_loss: 0.4951 - val_accuracy: 0.8887\n",
            "Epoch 64/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1337 - accuracy: 0.9282 - val_loss: 0.4588 - val_accuracy: 0.8809\n",
            "Epoch 65/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1359 - accuracy: 0.9278 - val_loss: 0.4753 - val_accuracy: 0.9036\n",
            "Epoch 66/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1286 - accuracy: 0.9298 - val_loss: 0.4248 - val_accuracy: 0.8783\n",
            "Epoch 67/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1286 - accuracy: 0.9305 - val_loss: 0.4939 - val_accuracy: 0.9063\n",
            "Epoch 68/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1329 - accuracy: 0.9279 - val_loss: 0.4496 - val_accuracy: 0.8912\n",
            "Epoch 69/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1295 - accuracy: 0.9300 - val_loss: 0.4340 - val_accuracy: 0.8861\n",
            "Epoch 70/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1352 - accuracy: 0.9294 - val_loss: 0.4760 - val_accuracy: 0.8988\n",
            "Epoch 71/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1305 - accuracy: 0.9308 - val_loss: 0.4442 - val_accuracy: 0.9016\n",
            "Epoch 72/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1279 - accuracy: 0.9313 - val_loss: 0.4928 - val_accuracy: 0.8865\n",
            "Epoch 73/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1277 - accuracy: 0.9329 - val_loss: 0.4374 - val_accuracy: 0.8885\n",
            "Epoch 74/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1322 - accuracy: 0.9286 - val_loss: 0.4499 - val_accuracy: 0.8873\n",
            "Epoch 75/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1309 - accuracy: 0.9308 - val_loss: 0.4088 - val_accuracy: 0.8941\n",
            "Epoch 76/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1265 - accuracy: 0.9328 - val_loss: 0.4202 - val_accuracy: 0.9060\n",
            "Epoch 77/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1287 - accuracy: 0.9325 - val_loss: 0.5266 - val_accuracy: 0.8896\n",
            "Epoch 78/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1319 - accuracy: 0.9282 - val_loss: 0.4856 - val_accuracy: 0.8944\n",
            "Epoch 79/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1316 - accuracy: 0.9315 - val_loss: 0.4803 - val_accuracy: 0.8952\n",
            "Epoch 80/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1291 - accuracy: 0.9315 - val_loss: 0.5469 - val_accuracy: 0.9101\n",
            "Epoch 81/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1248 - accuracy: 0.9336 - val_loss: 0.4762 - val_accuracy: 0.8877\n",
            "Epoch 82/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1254 - accuracy: 0.9340 - val_loss: 0.5144 - val_accuracy: 0.8887\n",
            "Epoch 83/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1283 - accuracy: 0.9298 - val_loss: 0.5689 - val_accuracy: 0.8972\n",
            "Epoch 84/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1270 - accuracy: 0.9324 - val_loss: 0.5581 - val_accuracy: 0.8936\n",
            "Epoch 85/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1235 - accuracy: 0.9338 - val_loss: 0.5211 - val_accuracy: 0.9104\n",
            "Epoch 86/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1260 - accuracy: 0.9352 - val_loss: 0.4814 - val_accuracy: 0.8971\n",
            "Epoch 87/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1246 - accuracy: 0.9349 - val_loss: 0.5600 - val_accuracy: 0.8971\n",
            "Epoch 88/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1256 - accuracy: 0.9344 - val_loss: 0.5110 - val_accuracy: 0.9076\n",
            "Epoch 89/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1268 - accuracy: 0.9340 - val_loss: 0.4904 - val_accuracy: 0.8959\n",
            "Epoch 90/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1287 - accuracy: 0.9332 - val_loss: 0.5131 - val_accuracy: 0.9076\n",
            "Epoch 91/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1191 - accuracy: 0.9372 - val_loss: 0.4261 - val_accuracy: 0.8931\n",
            "Epoch 92/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1238 - accuracy: 0.9358 - val_loss: 0.4982 - val_accuracy: 0.8885\n",
            "Epoch 93/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1274 - accuracy: 0.9333 - val_loss: 0.5430 - val_accuracy: 0.9005\n",
            "Epoch 94/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1224 - accuracy: 0.9353 - val_loss: 0.5088 - val_accuracy: 0.9069\n",
            "Epoch 95/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1241 - accuracy: 0.9344 - val_loss: 0.5843 - val_accuracy: 0.8952\n",
            "Epoch 96/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1225 - accuracy: 0.9371 - val_loss: 0.5395 - val_accuracy: 0.9095\n",
            "Epoch 97/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1213 - accuracy: 0.9365 - val_loss: 0.4639 - val_accuracy: 0.9071\n",
            "Epoch 98/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1243 - accuracy: 0.9370 - val_loss: 0.6056 - val_accuracy: 0.8965\n",
            "Epoch 99/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1179 - accuracy: 0.9401 - val_loss: 0.4929 - val_accuracy: 0.9008\n",
            "Epoch 100/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1185 - accuracy: 0.9384 - val_loss: 0.5345 - val_accuracy: 0.9089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd2508b1c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQg2TKLVXsmo"
      },
      "source": [
        "## Step 6. **Model with DNN layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhvdIfDwymA9",
        "outputId": "9448bc48-77c9-48e1-decf-578c2879cec8"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# input layer\n",
        "model.add(Dense(128,  activation='relu', input_shape = (71,)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "# hidden layer\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "# hidden layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten()) \n",
        "model.add(Dense(num_class))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 128)               9216      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 15)                975       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 59,663\n",
            "Trainable params: 59,663\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHcoSDdxymA-"
      },
      "source": [
        "learning_rates = 1e-4\r\n",
        "optim = tf.keras.optimizers.Adam(lr=learning_rates, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_dq7oCbymA_"
      },
      "source": [
        "## Step 7. Training the DNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuWGG2dNymBA",
        "outputId": "c718ea73-1a72-4717-ad51-d3b90c5e3b98"
      },
      "source": [
        "# fit network\n",
        "model.fit(X_train, y_train_v, epochs=100, batch_size=batch_size, validation_data=(X_val, y_val_v), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1337 - accuracy: 0.9391 - val_loss: 1.0509 - val_accuracy: 0.8891\n",
            "Epoch 2/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1341 - accuracy: 0.9387 - val_loss: 1.0689 - val_accuracy: 0.8905\n",
            "Epoch 3/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1357 - accuracy: 0.9385 - val_loss: 1.0054 - val_accuracy: 0.8895\n",
            "Epoch 4/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1346 - accuracy: 0.9396 - val_loss: 0.9986 - val_accuracy: 0.8893\n",
            "Epoch 5/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1344 - accuracy: 0.9389 - val_loss: 1.0265 - val_accuracy: 0.8912\n",
            "Epoch 6/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1344 - accuracy: 0.9390 - val_loss: 0.9785 - val_accuracy: 0.8892\n",
            "Epoch 7/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1349 - accuracy: 0.9390 - val_loss: 0.9900 - val_accuracy: 0.8903\n",
            "Epoch 8/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1339 - accuracy: 0.9392 - val_loss: 1.0127 - val_accuracy: 0.8897\n",
            "Epoch 9/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1328 - accuracy: 0.9396 - val_loss: 1.0093 - val_accuracy: 0.8895\n",
            "Epoch 10/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1337 - accuracy: 0.9392 - val_loss: 1.0354 - val_accuracy: 0.8907\n",
            "Epoch 11/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1334 - accuracy: 0.9397 - val_loss: 1.0179 - val_accuracy: 0.8901\n",
            "Epoch 12/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1345 - accuracy: 0.9391 - val_loss: 0.9966 - val_accuracy: 0.8911\n",
            "Epoch 13/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1341 - accuracy: 0.9393 - val_loss: 1.0156 - val_accuracy: 0.8892\n",
            "Epoch 14/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1339 - accuracy: 0.9392 - val_loss: 1.0039 - val_accuracy: 0.8899\n",
            "Epoch 15/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1334 - accuracy: 0.9391 - val_loss: 1.0699 - val_accuracy: 0.8897\n",
            "Epoch 16/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1335 - accuracy: 0.9394 - val_loss: 1.0719 - val_accuracy: 0.8903\n",
            "Epoch 17/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1338 - accuracy: 0.9395 - val_loss: 1.0420 - val_accuracy: 0.8884\n",
            "Epoch 18/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1339 - accuracy: 0.9396 - val_loss: 1.0489 - val_accuracy: 0.8899\n",
            "Epoch 19/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1327 - accuracy: 0.9394 - val_loss: 1.0560 - val_accuracy: 0.8900\n",
            "Epoch 20/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1332 - accuracy: 0.9396 - val_loss: 1.0339 - val_accuracy: 0.8904\n",
            "Epoch 21/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1337 - accuracy: 0.9392 - val_loss: 1.0560 - val_accuracy: 0.8896\n",
            "Epoch 22/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1326 - accuracy: 0.9402 - val_loss: 1.0573 - val_accuracy: 0.8897\n",
            "Epoch 23/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1328 - accuracy: 0.9396 - val_loss: 1.0762 - val_accuracy: 0.8900\n",
            "Epoch 24/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1335 - accuracy: 0.9395 - val_loss: 1.1100 - val_accuracy: 0.8913\n",
            "Epoch 25/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1322 - accuracy: 0.9407 - val_loss: 1.0763 - val_accuracy: 0.8908\n",
            "Epoch 26/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1322 - accuracy: 0.9398 - val_loss: 1.1124 - val_accuracy: 0.8896\n",
            "Epoch 27/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1329 - accuracy: 0.9396 - val_loss: 1.1115 - val_accuracy: 0.8903\n",
            "Epoch 28/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1332 - accuracy: 0.9395 - val_loss: 1.1014 - val_accuracy: 0.8913\n",
            "Epoch 29/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1330 - accuracy: 0.9398 - val_loss: 1.0930 - val_accuracy: 0.8927\n",
            "Epoch 30/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1334 - accuracy: 0.9400 - val_loss: 1.1330 - val_accuracy: 0.8904\n",
            "Epoch 31/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1324 - accuracy: 0.9402 - val_loss: 1.1404 - val_accuracy: 0.8912\n",
            "Epoch 32/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1326 - accuracy: 0.9395 - val_loss: 1.1305 - val_accuracy: 0.8897\n",
            "Epoch 33/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1333 - accuracy: 0.9390 - val_loss: 1.0882 - val_accuracy: 0.8909\n",
            "Epoch 34/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1325 - accuracy: 0.9394 - val_loss: 1.0978 - val_accuracy: 0.8897\n",
            "Epoch 35/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1323 - accuracy: 0.9398 - val_loss: 1.1773 - val_accuracy: 0.8904\n",
            "Epoch 36/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1325 - accuracy: 0.9399 - val_loss: 1.1464 - val_accuracy: 0.8900\n",
            "Epoch 37/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1323 - accuracy: 0.9396 - val_loss: 1.1378 - val_accuracy: 0.8908\n",
            "Epoch 38/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1314 - accuracy: 0.9397 - val_loss: 1.1255 - val_accuracy: 0.8903\n",
            "Epoch 39/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1317 - accuracy: 0.9396 - val_loss: 1.1841 - val_accuracy: 0.8901\n",
            "Epoch 40/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1326 - accuracy: 0.9403 - val_loss: 1.1580 - val_accuracy: 0.8908\n",
            "Epoch 41/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1317 - accuracy: 0.9401 - val_loss: 1.1714 - val_accuracy: 0.8912\n",
            "Epoch 42/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1322 - accuracy: 0.9400 - val_loss: 1.1641 - val_accuracy: 0.8912\n",
            "Epoch 43/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1323 - accuracy: 0.9397 - val_loss: 1.1888 - val_accuracy: 0.8900\n",
            "Epoch 44/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1317 - accuracy: 0.9398 - val_loss: 1.1905 - val_accuracy: 0.8908\n",
            "Epoch 45/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1319 - accuracy: 0.9397 - val_loss: 1.2020 - val_accuracy: 0.8924\n",
            "Epoch 46/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1317 - accuracy: 0.9396 - val_loss: 1.2137 - val_accuracy: 0.8909\n",
            "Epoch 47/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1316 - accuracy: 0.9398 - val_loss: 1.1874 - val_accuracy: 0.8915\n",
            "Epoch 48/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1311 - accuracy: 0.9402 - val_loss: 1.1906 - val_accuracy: 0.8907\n",
            "Epoch 49/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1323 - accuracy: 0.9400 - val_loss: 1.2311 - val_accuracy: 0.8931\n",
            "Epoch 50/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1310 - accuracy: 0.9402 - val_loss: 1.1986 - val_accuracy: 0.8908\n",
            "Epoch 51/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1315 - accuracy: 0.9398 - val_loss: 1.1562 - val_accuracy: 0.8884\n",
            "Epoch 52/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1309 - accuracy: 0.9400 - val_loss: 1.1801 - val_accuracy: 0.8901\n",
            "Epoch 53/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1312 - accuracy: 0.9406 - val_loss: 1.1212 - val_accuracy: 0.8888\n",
            "Epoch 54/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.9400 - val_loss: 1.1540 - val_accuracy: 0.8912\n",
            "Epoch 55/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1313 - accuracy: 0.9398 - val_loss: 1.1331 - val_accuracy: 0.8899\n",
            "Epoch 56/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1306 - accuracy: 0.9408 - val_loss: 1.1648 - val_accuracy: 0.8916\n",
            "Epoch 57/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1313 - accuracy: 0.9400 - val_loss: 1.0945 - val_accuracy: 0.8917\n",
            "Epoch 58/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1302 - accuracy: 0.9408 - val_loss: 1.1812 - val_accuracy: 0.8913\n",
            "Epoch 59/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1305 - accuracy: 0.9400 - val_loss: 1.1810 - val_accuracy: 0.8907\n",
            "Epoch 60/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.9398 - val_loss: 1.1808 - val_accuracy: 0.8912\n",
            "Epoch 61/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1308 - accuracy: 0.9402 - val_loss: 1.1652 - val_accuracy: 0.8911\n",
            "Epoch 62/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1306 - accuracy: 0.9401 - val_loss: 1.1921 - val_accuracy: 0.8908\n",
            "Epoch 63/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1305 - accuracy: 0.9403 - val_loss: 1.1630 - val_accuracy: 0.8915\n",
            "Epoch 64/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1300 - accuracy: 0.9402 - val_loss: 1.1854 - val_accuracy: 0.8909\n",
            "Epoch 65/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1304 - accuracy: 0.9403 - val_loss: 1.1964 - val_accuracy: 0.8925\n",
            "Epoch 66/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1307 - accuracy: 0.9399 - val_loss: 1.1605 - val_accuracy: 0.8911\n",
            "Epoch 67/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1300 - accuracy: 0.9406 - val_loss: 1.1846 - val_accuracy: 0.8901\n",
            "Epoch 68/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1293 - accuracy: 0.9409 - val_loss: 1.2301 - val_accuracy: 0.8909\n",
            "Epoch 69/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1299 - accuracy: 0.9405 - val_loss: 1.2432 - val_accuracy: 0.8908\n",
            "Epoch 70/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1306 - accuracy: 0.9399 - val_loss: 1.1842 - val_accuracy: 0.8904\n",
            "Epoch 71/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1308 - accuracy: 0.9397 - val_loss: 1.1823 - val_accuracy: 0.8912\n",
            "Epoch 72/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1299 - accuracy: 0.9402 - val_loss: 1.1564 - val_accuracy: 0.8921\n",
            "Epoch 73/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1301 - accuracy: 0.9402 - val_loss: 1.1765 - val_accuracy: 0.8900\n",
            "Epoch 74/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1292 - accuracy: 0.9409 - val_loss: 1.1398 - val_accuracy: 0.8920\n",
            "Epoch 75/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1299 - accuracy: 0.9405 - val_loss: 1.1292 - val_accuracy: 0.8931\n",
            "Epoch 76/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1298 - accuracy: 0.9410 - val_loss: 1.1961 - val_accuracy: 0.8912\n",
            "Epoch 77/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1290 - accuracy: 0.9406 - val_loss: 1.1998 - val_accuracy: 0.8903\n",
            "Epoch 78/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1304 - accuracy: 0.9401 - val_loss: 1.1982 - val_accuracy: 0.8913\n",
            "Epoch 79/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1289 - accuracy: 0.9403 - val_loss: 1.1815 - val_accuracy: 0.8911\n",
            "Epoch 80/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1285 - accuracy: 0.9409 - val_loss: 1.2132 - val_accuracy: 0.8904\n",
            "Epoch 81/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1302 - accuracy: 0.9408 - val_loss: 1.2063 - val_accuracy: 0.8912\n",
            "Epoch 82/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1290 - accuracy: 0.9406 - val_loss: 1.1912 - val_accuracy: 0.8905\n",
            "Epoch 83/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1291 - accuracy: 0.9409 - val_loss: 1.1580 - val_accuracy: 0.8891\n",
            "Epoch 84/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1286 - accuracy: 0.9410 - val_loss: 1.2023 - val_accuracy: 0.8912\n",
            "Epoch 85/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1296 - accuracy: 0.9404 - val_loss: 1.1728 - val_accuracy: 0.8919\n",
            "Epoch 86/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1288 - accuracy: 0.9408 - val_loss: 1.1958 - val_accuracy: 0.8901\n",
            "Epoch 87/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1283 - accuracy: 0.9408 - val_loss: 1.1717 - val_accuracy: 0.8915\n",
            "Epoch 88/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1273 - accuracy: 0.9413 - val_loss: 1.2114 - val_accuracy: 0.8917\n",
            "Epoch 89/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1278 - accuracy: 0.9406 - val_loss: 1.1738 - val_accuracy: 0.8911\n",
            "Epoch 90/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1292 - accuracy: 0.9411 - val_loss: 1.1554 - val_accuracy: 0.8896\n",
            "Epoch 91/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1277 - accuracy: 0.9409 - val_loss: 1.1595 - val_accuracy: 0.8924\n",
            "Epoch 92/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1284 - accuracy: 0.9409 - val_loss: 1.1654 - val_accuracy: 0.8912\n",
            "Epoch 93/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1279 - accuracy: 0.9407 - val_loss: 1.1632 - val_accuracy: 0.8909\n",
            "Epoch 94/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1274 - accuracy: 0.9412 - val_loss: 1.1755 - val_accuracy: 0.8901\n",
            "Epoch 95/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1278 - accuracy: 0.9413 - val_loss: 1.1518 - val_accuracy: 0.8901\n",
            "Epoch 96/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1275 - accuracy: 0.9410 - val_loss: 1.1777 - val_accuracy: 0.8923\n",
            "Epoch 97/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1273 - accuracy: 0.9409 - val_loss: 1.1618 - val_accuracy: 0.8923\n",
            "Epoch 98/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1268 - accuracy: 0.9414 - val_loss: 1.1095 - val_accuracy: 0.8913\n",
            "Epoch 99/100\n",
            "600/600 [==============================] - 1s 2ms/step - loss: 0.1273 - accuracy: 0.9410 - val_loss: 1.1392 - val_accuracy: 0.8919\n",
            "Epoch 100/100\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.1271 - accuracy: 0.9413 - val_loss: 1.1595 - val_accuracy: 0.8908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff93819bba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "8Y7P8jYVymBA",
        "outputId": "75175ac6-7b5a-4644-af78-65f3e7e115a9"
      },
      "source": [
        "# evaluate model\n",
        "accuracy = model.evaluate(X_test_r, y_test_v, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1e739510ce27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhXpjKmxaigy"
      },
      "source": [
        "## Step 8. KNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbrS4mGFagn7"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.metrics import accuracy_score "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdS-VHrqIvQH"
      },
      "source": [
        "features_order = ['Source Port', 'Destination Port',\r\n",
        "                      'Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets',\r\n",
        "                      'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\r\n",
        "                      'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std',\r\n",
        "                      'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total',\r\n",
        "                      'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\r\n",
        "                      'Bwd IAT Min', 'Fwd PSH Flags', 'Fwd URG Flags', 'Fwd Header Length', 'Bwd Header Length',\r\n",
        "                      'Fwd Packets/s', 'Bwd Packets/s', 'Min Packet Length', 'Max Packet Length', 'Packet Length Mean', 'Packet Length Std',\r\n",
        "                      'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\r\n",
        "                      'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size',\r\n",
        "                      'Avg Bwd Segment Size','Subflow Fwd Packets', 'Subflow Fwd Bytes',\r\n",
        "                      'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward', 'Init_Win_bytes_backward',\r\n",
        "                      'act_data_pkt_fwd', 'min_seg_size_forward', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\r\n",
        "                      'Idle Std', 'Idle Max', 'Idle Min']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1vbmR-lexwT"
      },
      "source": [
        "features=[\"Fwd Packet Length Max\",\"Flow IAT Std\",\"Fwd Packet Length Std\" ,\"Fwd IAT Total\",'Flow Packets/s', \"Fwd Packet Length Mean\",  \"Flow Bytes/s\",  \"Flow IAT Mean\", \"Bwd Packet Length Mean\",  \"Flow IAT Max\", \"Bwd Packet Length Std\", ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGiMP4URCr_1"
      },
      "source": [
        "### Import module for KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOSoDSnLISlh"
      },
      "source": [
        "First, convert numpy array to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "YKhW22bNHOjH",
        "outputId": "9891dd8a-b9d8-46a5-cedf-abe3154da0bb"
      },
      "source": [
        "df_train = pd.DataFrame(X_train, columns = features_order)\r\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000345</td>\n",
              "      <td>0.004161</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.750368e-09</td>\n",
              "      <td>2.006996e-06</td>\n",
              "      <td>1.670159e-03</td>\n",
              "      <td>0.003210</td>\n",
              "      <td>4.163675e-03</td>\n",
              "      <td>3.294118e-06</td>\n",
              "      <td>0.008277</td>\n",
              "      <td>0.004139</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.004167</td>\n",
              "      <td>4.110400e-03</td>\n",
              "      <td>0.008277</td>\n",
              "      <td>0.004170</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.004199</td>\n",
              "      <td>4.140332e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000833</td>\n",
              "      <td>0.000543</td>\n",
              "      <td>1.501095e-06</td>\n",
              "      <td>3.018877e-06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.001355</td>\n",
              "      <td>0.000681</td>\n",
              "      <td>4.633205e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.001451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.000833</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000543</td>\n",
              "      <td>2.283559e-06</td>\n",
              "      <td>0.125015</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.658003e-03</td>\n",
              "      <td>6.428571e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.333333e-07</td>\n",
              "      <td>6.554622e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000290</td>\n",
              "      <td>0.000290</td>\n",
              "      <td>6.493498e-03</td>\n",
              "      <td>1.298701e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000290</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.003967</td>\n",
              "      <td>0.003784</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001094</td>\n",
              "      <td>0.001304</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.991039e-10</td>\n",
              "      <td>4.203819e-08</td>\n",
              "      <td>8.823529e-02</td>\n",
              "      <td>0.174941</td>\n",
              "      <td>1.750000e-01</td>\n",
              "      <td>5.882353e-07</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>1.750000e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000579</td>\n",
              "      <td>0.000290</td>\n",
              "      <td>3.928256e-08</td>\n",
              "      <td>4.762654e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000524</td>\n",
              "      <td>0.003424</td>\n",
              "      <td>0.001594</td>\n",
              "      <td>2.537538e-06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004191</td>\n",
              "      <td>0.001094</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.003510</td>\n",
              "      <td>0.003601</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000345</td>\n",
              "      <td>0.004161</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.528986e-05</td>\n",
              "      <td>1.041666e-02</td>\n",
              "      <td>5.336134e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.250000e-07</td>\n",
              "      <td>5.462185e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.333333e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>7.812492e-03</td>\n",
              "      <td>1.562500e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.001054</td>\n",
              "      <td>0.000736</td>\n",
              "      <td>5.405405e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.001451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.000362</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>7.611864e-07</td>\n",
              "      <td>0.445572</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015444</td>\n",
              "      <td>0.025466</td>\n",
              "      <td>0.417300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.590488</td>\n",
              "      <td>0.496983</td>\n",
              "      <td>5.882509e-08</td>\n",
              "      <td>2.495034e-08</td>\n",
              "      <td>1.033613e-01</td>\n",
              "      <td>0.410165</td>\n",
              "      <td>8.183333e-01</td>\n",
              "      <td>4.201681e-08</td>\n",
              "      <td>0.818333</td>\n",
              "      <td>0.272500</td>\n",
              "      <td>0.791899</td>\n",
              "      <td>0.818333</td>\n",
              "      <td>4.166667e-08</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>3.358349e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001122</td>\n",
              "      <td>0.001520</td>\n",
              "      <td>1.201514e-08</td>\n",
              "      <td>5.089781e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.292143</td>\n",
              "      <td>0.630426</td>\n",
              "      <td>0.535618</td>\n",
              "      <td>2.865587e-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.643026</td>\n",
              "      <td>0.015444</td>\n",
              "      <td>0.590488</td>\n",
              "      <td>0.001122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000543</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.000905</td>\n",
              "      <td>1.470993e-03</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.003601</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.818333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.818333</td>\n",
              "      <td>0.818333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Source Port  Destination Port  Protocol  ...  Idle Std  Idle Max  Idle Min\n",
              "0          0.0          0.000000  0.000000  ...       0.0  0.000000  0.000000\n",
              "1          0.0          0.000000  0.000000  ...       0.0  0.000000  0.000000\n",
              "2          0.0          0.001094  0.001304  ...       0.0  0.000000  0.000000\n",
              "3          0.0          0.000000  0.000000  ...       0.0  0.000000  0.000000\n",
              "4          0.0          0.015444  0.025466  ...       0.0  0.818333  0.818333\n",
              "\n",
              "[5 rows x 71 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMdcfBB5MF2E"
      },
      "source": [
        "df_val = pd.DataFrame(X_val, columns = features_order)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc065YWMNPDZ"
      },
      "source": [
        "Select a subset of features from the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "CQcKmtHlKL3W",
        "outputId": "c578465b-ead9-46f3-9c19-a5c303a93d6c"
      },
      "source": [
        "df_sub=df_train.loc[:, features]\r\n",
        "df_sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.006996e-06</td>\n",
              "      <td>0.004170</td>\n",
              "      <td>4.163675e-03</td>\n",
              "      <td>4.140332e-03</td>\n",
              "      <td>4.110400e-03</td>\n",
              "      <td>0.003210</td>\n",
              "      <td>0.004167</td>\n",
              "      <td>0.008277</td>\n",
              "      <td>0.004139</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.000067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.658003e-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.333333e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.333333e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.203819e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.750000e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.750000e-01</td>\n",
              "      <td>0.174941</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.041666e-02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.250000e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.333333e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.495034e-08</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>8.183333e-01</td>\n",
              "      <td>3.358349e-08</td>\n",
              "      <td>4.166667e-08</td>\n",
              "      <td>0.410165</td>\n",
              "      <td>0.818333</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.272500</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.791899</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Fwd Packet Length Max  Flow IAT Std  ...  Flow IAT Max  Bwd Packet Length Std\n",
              "0           2.006996e-06      0.004170  ...      0.000063               0.000067\n",
              "1           8.658003e-03      0.000000  ...      0.000000               0.000000\n",
              "2           4.203819e-08      0.000000  ...      0.000000               0.000000\n",
              "3           1.041666e-02      0.000000  ...      0.000000               0.000000\n",
              "4           2.495034e-08      0.000006  ...      0.000011               0.791899\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "NfzSBQvYMKIu",
        "outputId": "034109f5-fdf4-4a51-83c7-3a64450bc70b"
      },
      "source": [
        "df_val_sub=df_val.loc[:, features]\r\n",
        "df_val_sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.007246</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.629147e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000474</td>\n",
              "      <td>8.344686e-03</td>\n",
              "      <td>8.382044e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001867</td>\n",
              "      <td>0.008343</td>\n",
              "      <td>0.991667</td>\n",
              "      <td>0.000358</td>\n",
              "      <td>0.002946</td>\n",
              "      <td>0.002530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.007663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.209963e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000484</td>\n",
              "      <td>1.672833e-02</td>\n",
              "      <td>8.382044e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001878</td>\n",
              "      <td>0.016715</td>\n",
              "      <td>0.991667</td>\n",
              "      <td>0.000357</td>\n",
              "      <td>0.002999</td>\n",
              "      <td>0.002537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.009804</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.617064e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Fwd Packet Length Max  Flow IAT Std  ...  Flow IAT Max  Bwd Packet Length Std\n",
              "0               0.007246      0.000000  ...      0.000000               0.000000\n",
              "1               0.000014      0.000474  ...      0.002946               0.002530\n",
              "2               0.007663      0.000000  ...      0.000000               0.000000\n",
              "3               0.000014      0.000484  ...      0.002999               0.002537\n",
              "4               0.009804      0.000000  ...      0.000000               0.000000\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1LdcE2INV4z"
      },
      "source": [
        "Convert dataframes to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZVfCiyLJkwo"
      },
      "source": [
        "X_train = df_sub.to_numpy()\r\n",
        "X_val = df_val_sub.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_Z_PAi7zntJ",
        "outputId": "149750b0-761c-4fe8-dcb7-341a27f0e2ed"
      },
      "source": [
        "for i in range(1,X_train.shape[1]+1):\r\n",
        "    knn=KNeighborsClassifier(n_neighbors=i)\r\n",
        "    model_knn=knn.fit(X_train,y_train)\r\n",
        "    yhat=model_knn.predict(X_val)\r\n",
        "    print(\"for \" , i,  \" as K, accuracy is : \", accuracy_score(y_val, yhat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for  1  as K, accuracy is :  0.6404\n",
            "for  2  as K, accuracy is :  0.6353333333333333\n",
            "for  3  as K, accuracy is :  0.6524\n",
            "for  4  as K, accuracy is :  0.6562666666666667\n",
            "for  5  as K, accuracy is :  0.6664\n",
            "for  6  as K, accuracy is :  0.6624\n",
            "for  7  as K, accuracy is :  0.6705333333333333\n",
            "for  8  as K, accuracy is :  0.6737333333333333\n",
            "for  9  as K, accuracy is :  0.6776\n",
            "for  10  as K, accuracy is :  0.6786666666666666\n",
            "for  11  as K, accuracy is :  0.6785333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSGgIaknOZ34"
      },
      "source": [
        "## Step 9. Random Foresty with DecisionTree "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7jbJl0fOaMB"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn17DazJOjsv",
        "outputId": "939129dd-67b5-4e0f-c560-cf31a387d5e8"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=10, random_state=SEED)\r\n",
        "clf.fit(X_train,y_train)\r\n",
        "    \r\n",
        "pred = clf.predict(X_val)\r\n",
        "val_acc = metrics.accuracy_score(y_val,pred)*100        \r\n",
        "print('val acc:',val_acc)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val acc: 72.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpXbErJHfbf3"
      },
      "source": [
        "## Step 10. CONV2D model\r\n",
        "Convert each example to a 6x4 color image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1SKdA7zkyA8"
      },
      "source": [
        "X_train_enlarge = np.append(X_train, np.zeros([len(X_train),1]),1)\r\n",
        "X_test_enlarge = np.append(X_test, np.zeros([len(X_test),1]),1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYmyATCFfptg"
      },
      "source": [
        "img_row = 6\r\n",
        "img_col = 4\r\n",
        "\r\n",
        "X_train_img = np.array([x.reshape(img_row, img_col, 3) for x in X_train_enlarge])\r\n",
        "X_test_img = np.array([x.reshape(img_row, img_col, 3) for x in X_test_enlarge])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "4R8X8qztlaB7",
        "outputId": "0dde3b35-7948-44a6-9017-24034bf22c78"
      },
      "source": [
        "#ploting images for data\r\n",
        "%matplotlib inline\r\n",
        "n = 40  # how many digits we will display\r\n",
        "plt.figure(figsize=(80, 30))\r\n",
        "for i in range(6,11):\r\n",
        "    # display original\r\n",
        "    ax = plt.subplot(1, n, i + 1)\r\n",
        "    plt.imshow(X_train_img[i])\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "plt.show()\r\n",
        "plt.close()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAACdCAYAAAB8SZgTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAFz0lEQVR4nO3ZvYtfZRrH4fvJRDRGV1gMKoIvqAFdENHKxlYQ7KzEwk6wEQtBEASFwIIsWiyilruI/4GliI1ooSBGCwWNICS+Y5y8OM7vsciOFsnADJzb8eteV5vD93eYJ2fmM2fGnLMAAFLs2+sbAADYDfECAEQRLwBAFPECAEQRLwBAlP27uXiMMatGy40crjtadrd8U++3bX/XtnzOnHORL/q58+OP5vyajcbfweYq4vwO1XVd01VVtb++aNs+cVnfva/OfFtz46c//fldWge7pquqaq3W27ZP7tHzt6t4ORcuFy9wR+d7ud5q2d3ySl3etv1a6wusVeP2gnqa9ndzl/9Vd+WXxm26rV1yoG1788zptu0lPVBPtu4fqkfbtp+/86m27fX3jiw7uK/n+9Ctq9tbdrdcUW+3bb95Ud/zt9rY/vnzZyMAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCijDnnzi8+OGbd1nQn7zXt/s9dq77t9/uma1VVc86xxNYYY+eHzWIWO7+1fbMO7F9i6jyX10bL7paT663zrRY7vxsvmvXM35eYOs/DZ75q2d3y30fWGtc3W5eXe/7GrMt6ft+/ZNX4A6qq/rZxadv2qbOn+raranOb8/PmBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIMuacO794jJ1fvEv/uKFr+Zyjnx9p2/742Tfath946d368MsfxxJbnedXtdY3XVUXr222bZ/tm66qqjlnwPmxHedXVXVf2/JjT3zTtv3afz6sE8fXnV/d3LZ8+93H27Y/+eBUnfpp84Ln580LABBFvAAAUcQLABBFvAAAUcQLABBFvAAAUcQLABBFvAAAUcQLABBFvAAAUcQLABBFvAAAUcQLABBFvAAAUcQLABBFvAAAUcQLABBFvAAAUcQLABBFvAAAUcQLABBFvAAAUfbv9Q1sOfpZ8weMp9qmv3/6ZNv2Zt3Ttr2o+Uvr/NlxS9v2qE/btmfb8rK673M07//faz/A19um53Mvtm1X/bNxezn9z1/f97jxzt1t27X6YNt/8uYFAIgiXgCAKOIFAIgiXgCAKOIFAIgiXgCAKOIFAIgiXgCAKOIFAIgiXgCAKOIFAIgiXgCAKOIFAIgiXgCAKOIFAIgiXgCAKOIFAIgiXgCAKOIFAIgiXgCAKOIFAIgiXgCAKOIFAIgy5pw7vvjAGPOmphs52rT7m2v7pq+8ZrRt//DRrI31ucgHjDF2ftgsZk7n1+vxxu1Xa84Tzi+Y56/b3jx/3rwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQZcw5d37xODzH+HfLjcx5b8vuX8GccyyxM8bVs+qhJaYu4F9Nu/mWOr+rxuH5YPU8fy+U5287Cc/fbfVqy+5vXj7eNv1Y23LVkSNVx44tdX6HZzU9fwfr/pbd3z/g5979JqdPV21uXvj8vHkBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKKMOefOLx7j66o61nc7XMD1c85DSww5vz3h/LI5v2zOL9u257ereAEA2Gv+bAQARBEvAEAU8QIARBEvAEAU8QIARBEvAEAU8QIARBEvAEAU8QIARPkV93YCcZ+b+EgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 5760x2160 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "8Jzhzsq0xkXH",
        "outputId": "4e2f7541-0f1a-4e10-832c-69dc4b3370a2"
      },
      "source": [
        "n = 40  # how many digits we will display\r\n",
        "plt.figure(figsize=(80, 30))\r\n",
        "for i in range(6,11):\r\n",
        "    # display original\r\n",
        "    ax = plt.subplot(1, n, i + 1)\r\n",
        "    plt.imshow(X_test_img[i])\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "plt.show()\r\n",
        "plt.close()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAACdCAYAAAB8SZgTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAErElEQVR4nO3bQWqkVRSG4XNTZdOR1oxE6IGO3JQLcO4S3IGbcFdOBCfiqCVNol1Vx4E0CJ1IBf5j8aWfZ/zz8dO3bvJSoVd3FwBAiqtLvwAAwFOIFwAgingBAKKIFwAgingBAKLsn/LwWst/TXrIGmzAPlV3ry2mnN9lbHt+m0x9uD2y+u/9uY/eyf3LdrWb2z6dqvvk/j3D+/ekeOFhu5fXY9vH+7ux7U1Nf5IOgz/g6ji4vaVVtX85svziMPt7dVf3Y9t3Q/8mVVV9mHtv/rG7fjW2fby73XDN/XvIpe6fPxsBAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQZXX3+Q/vrrqu9yMvclPvRnbfe/N2dH5Ud68tdtZa5x82m3F+VZ/urufGj3dj0/dVddzq/Par69Vui6kPfF7Hkd33/ngzOj/K/Xue9883LwBAFPECAEQRLwBAFPECAEQRLwBAFPECAEQRLwBAFPECAEQRLwBAFPECAEQRLwBAFPECAEQRLwBAFPECAEQRLwBAFPECAEQRLwBAFPECAEQRLwBAFPECAEQRLwBAFPECAEQRLwBAlNXd5z+81vkPs5nuXlvszJ7fbAd/sj+Nbb87jE1XVcr5TXsxtnzz2V9j27dvqw5H51f7wW3373/w/O6fb14AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIIl4AgCjiBQCIsr/0C7zXw/treP+j18fR+Xfrm7HtVT+PbU9/rrcyf/++mhu/+3Vu+/Tn3PaW/ACN5v494j/un29eAIAo4gUAiCJeAIAo4gUAiCJeAIAo4gUAiCJeAIAo4gUAiCJeAIAo4gUAiCJeAIAo4gUAiCJeAIAo4gUAiCJeAIAo4gUAiCJeAIAo4gUAiCJeAIAo4gUAiCJeAIAo4gUAiCJeAIAoq7vPf3it8x/+qHw/uP1Tdf+2tlhyfpfR3c5vlPvH49y/aZe5f755AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIIp4AQCiiBcAIMrq7rMf/nK97m/ru5EX+bF+GNl9Drp7bbGz1jr/sNnMduf3umvo/pX79yj3r6puIqfr9rbqcHD/kj12/3zzAgBEES8AQBTxAgBEES8AQBTxAgBEES8AQBTxAgBEES8AQBTxAgBEES8AQBTxAgBEES8AQBTxAgBEES8AQBTxAgBEES8AQBTxAgBEES8AQBTxAgBEES8AQBTxAgBEES8AQBTxAgBEWd19/sNr/V5Vv8y9Dg/4uru/2GLI+V2E88vm/LI5v2yPnt+T4gUA4NL82QgAiCJeAIAo4gUAiCJeAIAo4gUAiCJeAIAo4gUAiCJeAIAo4gUAiPI3tLrk/DuI3PsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 5760x2160 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnHm0-NankcX"
      },
      "source": [
        "Build a simple CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqVz8tQIpfn1"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Activation,Dropout\r\n",
        "from tensorflow.keras.constraints import max_norm"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqn8AWBor4d-"
      },
      "source": [
        "batch_size = 50 # increasing batch size with more gpu added\r\n",
        " \r\n",
        "num_class = 15                   # 15 intrusion classes, including benign traffic class\r\n",
        "epochs = 40"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFPWWw2AnnUa",
        "outputId": "fe8198d7-2e0f-4754-9675-cd6fa3ec3c36"
      },
      "source": [
        "model2d = Sequential()\r\n",
        "model2d.add(Conv2D(32, kernel_size=(1, 1), activation='relu', input_shape=(6,4,3)))\r\n",
        "#model2d.add(MaxPooling2D(pool_size=(1, 1)))\r\n",
        "model2d.add(Conv2D(32, kernel_size=(1,1), activation='relu'))\r\n",
        "#model2d.add(MaxPooling2D(pool_size=(1, 1)))\r\n",
        "model2d.add(Flatten())\r\n",
        "model2d.add(Dropout(0.2))\r\n",
        "model2d.add(Dense(512))\r\n",
        "model2d.add(Dense(num_class, activation='softmax'))\r\n",
        " \r\n",
        "model2d.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 6, 4, 32)          128       \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 6, 4, 32)          1056      \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               393728    \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 15)                7695      \n",
            "=================================================================\n",
            "Total params: 402,607\n",
            "Trainable params: 402,607\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pTciRO_r6g3",
        "outputId": "0469fe54-c943-46cc-c0bd-c1165d4d6341"
      },
      "source": [
        "# training\r\n",
        "model2d.compile(loss=tf.keras.losses.categorical_crossentropy,\r\n",
        "              optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\r\n",
        "              metrics=['accuracy'])\r\n",
        "model2d.fit(X_train_img, y_train_v,\r\n",
        "          batch_size=batch_size,\r\n",
        "          epochs=epochs,\r\n",
        "          verbose=1,\r\n",
        "          validation_data=(X_test_img, y_test_v))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.8867 - accuracy: 0.7097 - val_loss: 0.6294 - val_accuracy: 0.7941\n",
            "Epoch 2/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3918 - accuracy: 0.8499 - val_loss: 0.7202 - val_accuracy: 0.7810\n",
            "Epoch 3/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3246 - accuracy: 0.8677 - val_loss: 0.9063 - val_accuracy: 0.6654\n",
            "Epoch 4/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2886 - accuracy: 0.8757 - val_loss: 0.6517 - val_accuracy: 0.8183\n",
            "Epoch 5/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2745 - accuracy: 0.8792 - val_loss: 0.5756 - val_accuracy: 0.8436\n",
            "Epoch 6/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2612 - accuracy: 0.8830 - val_loss: 0.8948 - val_accuracy: 0.7433\n",
            "Epoch 7/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2485 - accuracy: 0.8851 - val_loss: 0.6870 - val_accuracy: 0.7960\n",
            "Epoch 8/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2493 - accuracy: 0.8846 - val_loss: 0.7454 - val_accuracy: 0.8266\n",
            "Epoch 9/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2459 - accuracy: 0.8881 - val_loss: 0.8669 - val_accuracy: 0.8351\n",
            "Epoch 10/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2419 - accuracy: 0.8913 - val_loss: 0.8579 - val_accuracy: 0.7864\n",
            "Epoch 11/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2384 - accuracy: 0.8917 - val_loss: 1.0851 - val_accuracy: 0.7410\n",
            "Epoch 12/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2275 - accuracy: 0.8958 - val_loss: 1.1562 - val_accuracy: 0.7553\n",
            "Epoch 13/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2343 - accuracy: 0.8895 - val_loss: 0.9008 - val_accuracy: 0.7787\n",
            "Epoch 14/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2283 - accuracy: 0.8942 - val_loss: 1.2740 - val_accuracy: 0.7645\n",
            "Epoch 15/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2284 - accuracy: 0.8939 - val_loss: 1.2163 - val_accuracy: 0.7662\n",
            "Epoch 16/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2310 - accuracy: 0.8923 - val_loss: 1.1586 - val_accuracy: 0.7624\n",
            "Epoch 17/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2260 - accuracy: 0.8958 - val_loss: 0.8030 - val_accuracy: 0.8238\n",
            "Epoch 18/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2302 - accuracy: 0.8929 - val_loss: 1.1616 - val_accuracy: 0.7615\n",
            "Epoch 19/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2197 - accuracy: 0.8973 - val_loss: 0.8676 - val_accuracy: 0.8097\n",
            "Epoch 20/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2229 - accuracy: 0.8963 - val_loss: 0.9029 - val_accuracy: 0.8051\n",
            "Epoch 21/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2252 - accuracy: 0.8934 - val_loss: 0.8549 - val_accuracy: 0.7945\n",
            "Epoch 22/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2249 - accuracy: 0.8946 - val_loss: 0.7519 - val_accuracy: 0.8566\n",
            "Epoch 23/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2260 - accuracy: 0.8931 - val_loss: 0.7619 - val_accuracy: 0.8573\n",
            "Epoch 24/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2197 - accuracy: 0.8973 - val_loss: 0.7906 - val_accuracy: 0.8355\n",
            "Epoch 25/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2257 - accuracy: 0.8963 - val_loss: 0.9844 - val_accuracy: 0.7847\n",
            "Epoch 26/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2227 - accuracy: 0.8953 - val_loss: 1.0340 - val_accuracy: 0.7947\n",
            "Epoch 27/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2260 - accuracy: 0.8962 - val_loss: 0.9296 - val_accuracy: 0.8043\n",
            "Epoch 28/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2332 - accuracy: 0.8946 - val_loss: 0.8312 - val_accuracy: 0.8690\n",
            "Epoch 29/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2305 - accuracy: 0.8952 - val_loss: 0.8550 - val_accuracy: 0.8395\n",
            "Epoch 30/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2296 - accuracy: 0.8949 - val_loss: 0.8744 - val_accuracy: 0.8597\n",
            "Epoch 31/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2250 - accuracy: 0.8956 - val_loss: 0.9445 - val_accuracy: 0.7975\n",
            "Epoch 32/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2269 - accuracy: 0.8974 - val_loss: 0.8793 - val_accuracy: 0.8714\n",
            "Epoch 33/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2301 - accuracy: 0.8955 - val_loss: 1.2238 - val_accuracy: 0.7750\n",
            "Epoch 34/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2280 - accuracy: 0.8966 - val_loss: 0.9055 - val_accuracy: 0.8461\n",
            "Epoch 35/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2250 - accuracy: 0.8999 - val_loss: 0.9819 - val_accuracy: 0.8438\n",
            "Epoch 36/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2246 - accuracy: 0.9011 - val_loss: 0.8793 - val_accuracy: 0.8525\n",
            "Epoch 37/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2280 - accuracy: 0.8984 - val_loss: 0.9856 - val_accuracy: 0.8147\n",
            "Epoch 38/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2332 - accuracy: 0.8962 - val_loss: 1.1195 - val_accuracy: 0.7629\n",
            "Epoch 39/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2307 - accuracy: 0.8989 - val_loss: 1.1902 - val_accuracy: 0.7779\n",
            "Epoch 40/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2222 - accuracy: 0.8983 - val_loss: 1.1278 - val_accuracy: 0.7499\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa0d41b7080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEuBVj6zzp1I"
      },
      "source": [
        "## Step 11. CONV2D with 9x8 gray image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iVF5urfzzMN"
      },
      "source": [
        "X_train_enlarge = np.append(X_train, np.zeros([len(X_train),1]),1)\r\n",
        "X_test_enlarge = np.append(X_test, np.zeros([len(X_test),1]),1)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgiNKZx30DA_"
      },
      "source": [
        "img_row = 9\r\n",
        "img_col = 8\r\n",
        "\r\n",
        "X_train_gray = np.array([x.reshape(img_row, img_col,1) for x in X_train_enlarge])\r\n",
        "train_gray = np.array([x.reshape(img_row, img_col) for x in X_train_enlarge])\r\n",
        "X_test_gray = np.array([x.reshape(img_row, img_col,1) for x in X_test_enlarge])\r\n",
        "test_gray = np.array([x.reshape(img_row, img_col) for x in X_test_enlarge])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "321IH1HcDBrr",
        "outputId": "769b64dc-2706-421b-ea9d-d4ac09cf0d98"
      },
      "source": [
        "X_train_gray.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 9, 8, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "9Y0bn6k90bD5",
        "outputId": "8cae155b-5fa7-4c08-ee99-ee2c09d2b757"
      },
      "source": [
        "n = 40  # how many digits we will display\r\n",
        "plt.figure(figsize=(80, 30))\r\n",
        "for i in range(6,11):\r\n",
        "    # display original\r\n",
        "    ax = plt.subplot(1, n, i + 1)\r\n",
        "    plt.imshow(train_gray[i])\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "plt.show()\r\n",
        "plt.close()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 5760x2160 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "L7-UXgrv-rxv",
        "outputId": "b5e52c11-b53d-4565-c07d-c9f48d3351a4"
      },
      "source": [
        "n = 40  # how many digits we will display\r\n",
        "plt.figure(figsize=(80, 30))\r\n",
        "for i in range(6,11):\r\n",
        "    # display original\r\n",
        "    ax = plt.subplot(1, n, i + 1)\r\n",
        "    plt.imshow(test_gray[i])\r\n",
        "    plt.gray()\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "plt.show()\r\n",
        "plt.close()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAB6CAYAAAB3CLMpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAEr0lEQVR4nO3dQU4ySRjHYUoaFTXhCLPxCFzMG3gDL+YVXMza2RDFiEF6DjCS6ddpBv/4POs3Zcf6ivyC+bpa3/cTAIAUZ8d+AACACvECAEQRLwBAFPECAEQRLwBAlK4y3FrzX5OOoO/7NsY69u84EvavtVEeca/q/2qsPE/12Xe7XWk+Yf/YL2H/nL/99u1fKV7gWLqu9k91u90e6ElyVH5ns9mstHb1A2iz2ZTmLy4uBs+endW+QH57eyvNw3c4f18b6/z5sxEAEEW8AABRxAsAEEW8AABRxAsAEEW8AABRxAsAEEW8AABRxAsAEOWgb9idTqeDZ8/Pz0trV9/qt16vS/PX19eDZz8+PkprX11dDZ59fX0trf1vKnvy+fk56s/+L7wxt66yf9VXfFffCFr1/v5+0PUTVM7q5eVlae3qG6tXq1VpfrFYDJ6tfsZVPpvH/vyscP4OyzcvAEAU8QIARBEvAEAU8QIARBEvAEAU8QIARBEvAEAU8QIARBEvAEAU8QIARBEvAECU1vf94OHpdNrP5/PB89X7hPha3/e1iy/2aK0N32xGk7B/lfu2JpPJZLPZlOard5dV7np5e3srrV011v51Xdff3NwMnq/eJ8TXnL/TPH++eQEAoogXACCKeAEAoogXACCKeAEAoogXACCKeAEAoogXACCKeAEAoogXACBK6XoAr5c/joTXW/80Z2fDu3w6nZbWrpyZ7XZr/8LZv5+l67rBs85fPtcDAAAnQbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQZfglEYymcjfOcrk84JOcrt1ud5DZY2qtTWaz2eD5+Xw+eLb6O3h5eSnN/yTOX7btdnuUn+v8jWOs8+ebFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgSqvcM9BaGz7MaPq+b2Oss1wu+8fHxzGW+ofWRnnEvW5vb0vzT09Pg2crZ+A7xtq/5PNX3b/n5+fBs+v1urR21w2/0m2z2Ux2u91Rzt+hz9Rv4fyd5vnzzQsAEEW8AABRxAsAEEW8AABRxAsAEEW8AABRxAsAEEW8AABRxAsAEEW8AABRxAsAEMXdRgHczZHN/mWzf9nsX7Z9++ebFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKKIFwAgingBAKJ0x36A77q7uzvo+g8PD4Nn7+/vS2tX55lMWqu94bty7QV11fNXOU9Vzl+d85TN+fPNCwAQRrwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQRbwAAFHECwAQpVXurGitueDiCPq+r11Esof9Ow77l+0U92+xWJTmV6vVQdevqD7LKe7fb7Jv/3zzAgBEES8AQBTxAgBEES8AQBTxAgBEES8AQBTxAgBEES8AQBTxAgBEES8AQBTxAgBE6Yrzf00mkz8P8SDs9ceIa9m//5/9y3aS+1e9H+inrV9wkvv3i+zdv9LFjAAAx+bPRgBAFPECAEQRLwBAFPECAEQRLwBAFPECAEQRLwBAFPECAEQRLwBAlL8B2YNYyADzxXAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 5760x2160 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3uWCvuS-6xc"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Activation,Dropout\r\n",
        "from tensorflow.keras.constraints import max_norm"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x8EsYUR-96P"
      },
      "source": [
        "batch_size = 50 # increasing batch size with more gpu added\r\n",
        " \r\n",
        "num_class = 15                   # 15 intrusion classes, including benign traffic class\r\n",
        "epochs = 40"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixx6i4LF_BtR",
        "outputId": "16bb182a-35e9-40ba-8162-0c65d1d8d61a"
      },
      "source": [
        "model2d_g = Sequential()\r\n",
        "model2d_g.add(Conv2D(32, kernel_size=(1, 1), padding = 'same', activation='relu', input_shape=(9,8,1)))\r\n",
        "model2d_g.add(Conv2D(64, kernel_size=(1,1), padding = 'same', activation='relu'))\r\n",
        "model2d_g.add(Flatten())\r\n",
        "model2d_g.add(Dropout(0.1))\r\n",
        "model2d_g.add(Dense(512))\r\n",
        "model2d_g.add(Dense(num_class, activation='softmax'))\r\n",
        " \r\n",
        "model2d_g.summary()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_30 (Conv2D)           (None, 9, 8, 32)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 9, 8, 64)          2112      \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 512)               2359808   \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 15)                7695      \n",
            "=================================================================\n",
            "Total params: 2,369,679\n",
            "Trainable params: 2,369,679\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J4EhQ2c_Pdm",
        "outputId": "f57a7085-319f-4f8f-eafe-80dad6635126"
      },
      "source": [
        "# training\r\n",
        "model2d_g.compile(loss=tf.keras.losses.categorical_crossentropy,\r\n",
        "              optimizer=tf.keras.optimizers.RMSprop(lr=0.001), #SGD(lr=0.01),\r\n",
        "              metrics=['accuracy'])\r\n",
        "model2d_g.fit(X_train_gray, y_train_v,\r\n",
        "          batch_size=batch_size,\r\n",
        "          epochs=epochs,\r\n",
        "          verbose=1,\r\n",
        "          validation_data=(X_test_gray, y_test_v))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3443 - accuracy: 0.8623 - val_loss: 0.5925 - val_accuracy: 0.7883\n",
            "Epoch 2/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.3019 - accuracy: 0.8730 - val_loss: 0.5960 - val_accuracy: 0.8020\n",
            "Epoch 3/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2801 - accuracy: 0.8816 - val_loss: 0.5272 - val_accuracy: 0.8633\n",
            "Epoch 4/40\n",
            "1200/1200 [==============================] - 4s 4ms/step - loss: 0.2686 - accuracy: 0.8827 - val_loss: 0.5949 - val_accuracy: 0.8285\n",
            "Epoch 5/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2573 - accuracy: 0.8861 - val_loss: 0.5476 - val_accuracy: 0.8584\n",
            "Epoch 6/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2555 - accuracy: 0.8857 - val_loss: 0.6924 - val_accuracy: 0.7930\n",
            "Epoch 7/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2442 - accuracy: 0.8866 - val_loss: 0.5726 - val_accuracy: 0.8537\n",
            "Epoch 8/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2469 - accuracy: 0.8885 - val_loss: 0.5714 - val_accuracy: 0.8375\n",
            "Epoch 9/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2412 - accuracy: 0.8882 - val_loss: 0.6233 - val_accuracy: 0.8762\n",
            "Epoch 10/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2402 - accuracy: 0.8905 - val_loss: 0.7208 - val_accuracy: 0.8279\n",
            "Epoch 11/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2393 - accuracy: 0.8905 - val_loss: 0.5914 - val_accuracy: 0.8727\n",
            "Epoch 12/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2329 - accuracy: 0.8909 - val_loss: 0.6395 - val_accuracy: 0.8572\n",
            "Epoch 13/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2319 - accuracy: 0.8921 - val_loss: 0.6601 - val_accuracy: 0.8471\n",
            "Epoch 14/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2352 - accuracy: 0.8905 - val_loss: 0.8731 - val_accuracy: 0.7547\n",
            "Epoch 15/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2370 - accuracy: 0.8907 - val_loss: 0.7803 - val_accuracy: 0.8482\n",
            "Epoch 16/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2273 - accuracy: 0.8937 - val_loss: 1.0741 - val_accuracy: 0.7394\n",
            "Epoch 17/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2295 - accuracy: 0.8913 - val_loss: 1.0848 - val_accuracy: 0.7651\n",
            "Epoch 18/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2288 - accuracy: 0.8937 - val_loss: 1.1330 - val_accuracy: 0.7633\n",
            "Epoch 19/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2319 - accuracy: 0.8932 - val_loss: 0.9038 - val_accuracy: 0.8614\n",
            "Epoch 20/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2289 - accuracy: 0.8916 - val_loss: 1.1017 - val_accuracy: 0.7767\n",
            "Epoch 21/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2247 - accuracy: 0.8945 - val_loss: 1.2114 - val_accuracy: 0.6776\n",
            "Epoch 22/40\n",
            "1200/1200 [==============================] - 4s 4ms/step - loss: 0.2349 - accuracy: 0.8914 - val_loss: 1.2530 - val_accuracy: 0.7369\n",
            "Epoch 23/40\n",
            "1200/1200 [==============================] - 4s 4ms/step - loss: 0.2300 - accuracy: 0.8920 - val_loss: 1.0846 - val_accuracy: 0.7473\n",
            "Epoch 24/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2330 - accuracy: 0.8895 - val_loss: 1.0541 - val_accuracy: 0.7880\n",
            "Epoch 25/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2288 - accuracy: 0.8944 - val_loss: 0.9389 - val_accuracy: 0.8219\n",
            "Epoch 26/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2271 - accuracy: 0.8948 - val_loss: 1.2123 - val_accuracy: 0.7909\n",
            "Epoch 27/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2343 - accuracy: 0.8937 - val_loss: 0.8094 - val_accuracy: 0.8217\n",
            "Epoch 28/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2253 - accuracy: 0.8957 - val_loss: 1.0117 - val_accuracy: 0.7888\n",
            "Epoch 29/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2239 - accuracy: 0.8956 - val_loss: 1.7060 - val_accuracy: 0.6344\n",
            "Epoch 30/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2282 - accuracy: 0.8949 - val_loss: 1.0019 - val_accuracy: 0.8415\n",
            "Epoch 31/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2332 - accuracy: 0.8934 - val_loss: 1.2533 - val_accuracy: 0.7495\n",
            "Epoch 32/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2286 - accuracy: 0.8935 - val_loss: 1.1413 - val_accuracy: 0.8295\n",
            "Epoch 33/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2282 - accuracy: 0.8938 - val_loss: 0.9026 - val_accuracy: 0.8334\n",
            "Epoch 34/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2341 - accuracy: 0.8916 - val_loss: 1.0685 - val_accuracy: 0.7963\n",
            "Epoch 35/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2421 - accuracy: 0.8899 - val_loss: 1.0525 - val_accuracy: 0.7882\n",
            "Epoch 36/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2345 - accuracy: 0.8933 - val_loss: 0.9315 - val_accuracy: 0.8244\n",
            "Epoch 37/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2306 - accuracy: 0.8923 - val_loss: 1.2779 - val_accuracy: 0.7908\n",
            "Epoch 38/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2366 - accuracy: 0.8919 - val_loss: 1.0751 - val_accuracy: 0.8189\n",
            "Epoch 39/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2300 - accuracy: 0.8930 - val_loss: 0.8858 - val_accuracy: 0.8311\n",
            "Epoch 40/40\n",
            "1200/1200 [==============================] - 4s 3ms/step - loss: 0.2342 - accuracy: 0.8900 - val_loss: 1.2160 - val_accuracy: 0.7560\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa0be66a320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-sgJteF-t7M"
      },
      "source": [
        "## Step 12. RNN Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78CA10VnqsdX"
      },
      "source": [
        "The dataset is not right. It should be time serial data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfllyVNUkzOP"
      },
      "source": [
        "from tensorflow.keras.layers import SimpleRNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1EthXf--2s6",
        "outputId": "2bccdc8d-8587-43e3-959d-3bf953614177"
      },
      "source": [
        "modelrnn = Sequential()\r\n",
        "modelrnn.add(SimpleRNN(120, input_shape = (71,1), return_sequences=True))\r\n",
        "modelrnn.add(Dropout(0.2))\r\n",
        "\r\n",
        "modelrnn.add(SimpleRNN(120, return_sequences=True))\r\n",
        "modelrnn.add(Dropout(0.2))\r\n",
        "\r\n",
        "modelrnn.add(SimpleRNN(120, return_sequences=False))\r\n",
        "modelrnn.add(Dropout(0.2))\r\n",
        "\r\n",
        "# multiclass\r\n",
        "modelrnn.add(Dense(num_class))\r\n",
        "modelrnn.add(Activation('softmax'))\r\n",
        "\r\n",
        "modelrnn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_7 (SimpleRNN)     (None, 71, 120)           14640     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 71, 120)           0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_8 (SimpleRNN)     (None, 71, 120)           28920     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 71, 120)           0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_9 (SimpleRNN)     (None, 120)               28920     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 15)                1815      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 74,295\n",
            "Trainable params: 74,295\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItOu4406lS7T"
      },
      "source": [
        "learning_rates = 1e-4\r\n",
        "optim = tf.keras.optimizers.Adam(lr=learning_rates, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\r\n",
        "modelrnn.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "88RBpD3GlVBr",
        "outputId": "7b67e028-2b61-4879-90d5-28f70f03bb66"
      },
      "source": [
        "# fit network\r\n",
        "modelrnn.fit(X_train, y_train_v, epochs=100, batch_size=batch_size, validation_data=(X_val, y_val_v), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-f43279c74dd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodelrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:223 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_5 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (100, 71)\n"
          ]
        }
      ]
    }
  ]
}