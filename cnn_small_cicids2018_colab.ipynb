{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "cnn_small_cicids2018_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwangliberty/AIoTDesign-Frontend/blob/master/cnn_small_cicids2018_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HakdgCXBymAw"
      },
      "source": [
        "# Intrusion Detection by using small CICIDS 2018 DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqdB1_F0ymAz"
      },
      "source": [
        "import os\n",
        "from os.path import join\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-kNtwdKymAz"
      },
      "source": [
        "## Step 1. Read cleaned CICIDS2018 small dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is2az0Giy0iC"
      },
      "source": [
        "Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9zJ-0oQy1Gy",
        "outputId": "eb0c2acb-f8e0-4282-870a-349f2fcc5db5"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E17GpxaNymAz"
      },
      "source": [
        "# load train data\n",
        "cleanfile = '/content/drive/My Drive/CICIDS2018/xtrain_small.csv'\n",
        "labelfile = '/content/drive/My Drive/CICIDS2018/ytrain_small.csv'\n",
        "xtestsmall = '/content/drive/My Drive/CICIDS2018/xtest_small.csv'\n",
        "ytestsmall = '/content/drive/My Drive/CICIDS2018/ytest_small.csv'\n",
        "SEED=2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "YXMkWoEUymA0",
        "outputId": "aa1e0a17-4255-4912-cacc-c89815bb50d3"
      },
      "source": [
        "X_train = pd.read_csv(cleanfile, skiprows=0,index_col=0) \n",
        "y_train = pd.read_csv(labelfile, skiprows=0,index_col=0)  \n",
        "X_test = pd.read_csv(xtestsmall, skiprows=0, index_col=0) \n",
        "y_test = pd.read_csv(ytestsmall, skiprows=0,index_col=0) \n",
        "X_train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1755722.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9743.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>205.275583</td>\n",
              "      <td>9743.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9743.0</td>\n",
              "      <td>9743.0</td>\n",
              "      <td>9743.0</td>\n",
              "      <td>9743.00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9743.0</td>\n",
              "      <td>9743.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>205.275583</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6156600.0</td>\n",
              "      <td>445.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>111085.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>455.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.833333</td>\n",
              "      <td>62.936211</td>\n",
              "      <td>145.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.600000</td>\n",
              "      <td>69.758870</td>\n",
              "      <td>7138.677589</td>\n",
              "      <td>99.023270</td>\n",
              "      <td>11108.500000</td>\n",
              "      <td>1.422834e+04</td>\n",
              "      <td>29284.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>111051.0</td>\n",
              "      <td>22210.20</td>\n",
              "      <td>1.245618e+04</td>\n",
              "      <td>29356.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>110986.0</td>\n",
              "      <td>27746.500000</td>\n",
              "      <td>1196.308349</td>\n",
              "      <td>29371.0</td>\n",
              "      <td>26744.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>54.012693</td>\n",
              "      <td>45.010577</td>\n",
              "      <td>0.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>66.083333</td>\n",
              "      <td>63.402693</td>\n",
              "      <td>4019.901515</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.090909</td>\n",
              "      <td>75.833333</td>\n",
              "      <td>67.600000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>455.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>8192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>242193.0</td>\n",
              "      <td>8080.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10686.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>108.666667</td>\n",
              "      <td>188.216188</td>\n",
              "      <td>112.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.250000</td>\n",
              "      <td>53.767245</td>\n",
              "      <td>42579.075430</td>\n",
              "      <td>655.062699</td>\n",
              "      <td>1781.000000</td>\n",
              "      <td>3.912594e+03</td>\n",
              "      <td>9758.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>563.0</td>\n",
              "      <td>281.50</td>\n",
              "      <td>3.245620e+02</td>\n",
              "      <td>511.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>10196.0</td>\n",
              "      <td>3398.666667</td>\n",
              "      <td>5510.518064</td>\n",
              "      <td>9758.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>280.741157</td>\n",
              "      <td>374.321542</td>\n",
              "      <td>0.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>56.875000</td>\n",
              "      <td>115.406657</td>\n",
              "      <td>13318.696430</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>108.666667</td>\n",
              "      <td>32.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>8192.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6934977.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>285714.285714</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>142857.142857</td>\n",
              "      <td>142857.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4505141.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5007525.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>646.0</td>\n",
              "      <td>364.0</td>\n",
              "      <td>646.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>129.200000</td>\n",
              "      <td>288.899983</td>\n",
              "      <td>364.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>121.333333</td>\n",
              "      <td>210.155498</td>\n",
              "      <td>201.696447</td>\n",
              "      <td>1.597596</td>\n",
              "      <td>715360.714286</td>\n",
              "      <td>1.868948e+06</td>\n",
              "      <td>4953524.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5007525.0</td>\n",
              "      <td>1251881.25</td>\n",
              "      <td>2.467885e+06</td>\n",
              "      <td>4953524.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>3255.0</td>\n",
              "      <td>1627.500000</td>\n",
              "      <td>634.274783</td>\n",
              "      <td>2076.0</td>\n",
              "      <td>1179.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.998497</td>\n",
              "      <td>0.599098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>646.0</td>\n",
              "      <td>112.222222</td>\n",
              "      <td>233.577491</td>\n",
              "      <td>54558.444444</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>129.200000</td>\n",
              "      <td>121.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>646.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>364.0</td>\n",
              "      <td>8192.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0       1    2          3    4    5  ...   73   74   75   76   77   78\n",
              "0  1755722.0    80.0  6.0     9743.0  2.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "1  6156600.0   445.0  6.0   111085.0  6.0  5.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2   242193.0  8080.0  6.0    10686.0  3.0  4.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3  6934977.0    22.0  6.0        7.0  1.0  1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4  4505141.0    80.0  6.0  5007525.0  5.0  3.0  ...  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "\n",
              "[5 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPLtWtJ8ymA1",
        "outputId": "971ab720-6af2-48cf-ac4c-1f8c09c94a02"
      },
      "source": [
        "# Here we can see the number of rows and columns for each table.\n",
        "print(y_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtjNVDHfymA1"
      },
      "source": [
        "## Step 2. Normalization\n",
        "\n",
        "The continuous feature values are normalized into the same feature space. This is important when using features that have different measurements, and is a general requirement of many machine learning algorithms. Therefore, the values for this dataset are also normalized using the Min-Max scaling technique, bringing them all within a range of [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euTfYdWHymA2"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5JH_i4EymA2",
        "outputId": "8c565503-8c13-415e-80b0-37f0dfa1dd16"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_train"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1888032 , 0.00122085, 0.35294118, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.66241015, 0.00679099, 0.35294118, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.02592255, 0.12330607, 0.35294118, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.3534946 , 0.83272799, 0.35294118, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.82190572, 0.00122085, 1.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.51949634, 0.00679099, 0.35294118, ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PuA6ri3ymA2",
        "outputId": "b6355283-a6d1-4e08-e407-f5f970f92562"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry0R9AFFymA3"
      },
      "source": [
        "X_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeFIseICymA3",
        "outputId": "fd9520f4-7cf3-4630-d2e3-e00c56ba7754"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7500, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XayluHqdymA3"
      },
      "source": [
        "y_train and y_test have to be one-hot-encoded. That means they must have dimension (number_of_samples, 15), where 15 denotes number of classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pMxFRGCymA4",
        "outputId": "f6aabc44-d933-488c-d298-a6dbbd039adc"
      },
      "source": [
        "y_vector = y_train.values.tolist()\n",
        "print(len(y_vector))\n",
        "y_test_v = y_test.values.tolist()\n",
        "print(len(y_test_v))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30000\n",
            "7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na5t3wpmymA4",
        "outputId": "bd373cd0-c12f-403b-e5de-9b1e683836be"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_vector, 15)\n",
        "y_test = to_categorical(y_test_v, 15)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000, 15)\n",
            "(7500, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79Q2ezxEymA6"
      },
      "source": [
        "## Step 3. Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYdmYYyWymA6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Flatten, Dense, Activation,Dropout\n",
        "from tensorflow.keras.constraints import max_norm"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VinchNXyymA7",
        "outputId": "a97fb98d-8dfd-4418-cff1-c3c278c3d9d4"
      },
      "source": [
        "#hyper-params\n",
        "batch_size = 512 # increasing batch size with more gpu added\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "num_class = 15                   # 15 intrusion classes, including benign traffic class\n",
        "num_epochs = 90\n",
        "learning_rates = 0.0001\n",
        "\n",
        "optim = tf.keras.optimizers.Adam(lr=learning_rates, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "print(input_dim)\n",
        "print(num_class)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SeAQGIoymA8",
        "outputId": "edf000bf-4126-4fa4-ce73-3e4242a22d62"
      },
      "source": [
        "#X_train_r = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_train_r = np.zeros((len(X_train), input_dim, 1))\n",
        "X_train_r[:, :, 0] = X_train[:, :input_dim]\n",
        "print(X_train_r.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000, 79, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B96MRlI_ymA8",
        "outputId": "ea651d86-a1e6-406c-a590-a42133c865da"
      },
      "source": [
        "X_test_r = np.zeros((len(X_test), input_dim, 1))\n",
        "X_test_r[:, :, 0] = X_test[:, :input_dim]\n",
        "print(X_test_r.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7500, 79, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhvdIfDwymA9",
        "outputId": "44f0fb9a-c116-42a3-a9eb-04c6b07a3325"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# input layer\n",
        "model.add(Conv1D(filters=64, kernel_size=13, padding='same', input_shape=(79,1)))\n",
        "model.add(BatchNormalization(axis=1))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model.add(Conv1D(filters=128, kernel_size=5))\n",
        "model.add(BatchNormalization(axis=1))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model.add(Conv1D(filters=256, kernel_size=5))\n",
        "model.add(BatchNormalization(axis=1))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv1D(filters=512, kernel_size=3))\n",
        "model.add(BatchNormalization(axis=1))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Conv1D(filters=256, kernel_size=3))\n",
        "model.add(BatchNormalization(axis=1))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(num_class))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_165 (Conv1D)          (None, 79, 64)            896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_164 (Bat (None, 79, 64)            316       \n",
            "_________________________________________________________________\n",
            "activation_196 (Activation)  (None, 79, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_53 (MaxPooling (None, 39, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_166 (Conv1D)          (None, 35, 128)           41088     \n",
            "_________________________________________________________________\n",
            "batch_normalization_165 (Bat (None, 35, 128)           140       \n",
            "_________________________________________________________________\n",
            "activation_197 (Activation)  (None, 35, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_54 (MaxPooling (None, 17, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_167 (Conv1D)          (None, 13, 256)           164096    \n",
            "_________________________________________________________________\n",
            "batch_normalization_166 (Bat (None, 13, 256)           52        \n",
            "_________________________________________________________________\n",
            "activation_198 (Activation)  (None, 13, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_168 (Conv1D)          (None, 11, 512)           393728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_167 (Bat (None, 11, 512)           44        \n",
            "_________________________________________________________________\n",
            "activation_199 (Activation)  (None, 11, 512)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_169 (Conv1D)          (None, 9, 256)            393472    \n",
            "_________________________________________________________________\n",
            "batch_normalization_168 (Bat (None, 9, 256)            36        \n",
            "_________________________________________________________________\n",
            "activation_200 (Activation)  (None, 9, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_32 (Flatten)         (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 100)               230500    \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 15)                1515      \n",
            "_________________________________________________________________\n",
            "activation_201 (Activation)  (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 1,225,883\n",
            "Trainable params: 1,225,589\n",
            "Non-trainable params: 294\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHcoSDdxymA-"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy']) "
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_dq7oCbymA_"
      },
      "source": [
        "## Step 4. Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuWGG2dNymBA",
        "outputId": "9f112a0f-13d7-477b-a31a-e3f45549f3c3"
      },
      "source": [
        "# fit network\n",
        "model.fit(X_train_r, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_test_r, y_test), verbose=1)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "59/59 [==============================] - 4s 40ms/step - loss: 1.4792 - accuracy: 0.5338 - val_loss: 2.9308 - val_accuracy: 0.0667\n",
            "Epoch 2/90\n",
            "59/59 [==============================] - 2s 28ms/step - loss: 0.2848 - accuracy: 0.8891 - val_loss: 3.3144 - val_accuracy: 0.0667\n",
            "Epoch 3/90\n",
            "59/59 [==============================] - 2s 28ms/step - loss: 0.2275 - accuracy: 0.9047 - val_loss: 3.4880 - val_accuracy: 0.0820\n",
            "Epoch 4/90\n",
            "59/59 [==============================] - 2s 28ms/step - loss: 0.2112 - accuracy: 0.9110 - val_loss: 2.8456 - val_accuracy: 0.0947\n",
            "Epoch 5/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1943 - accuracy: 0.9177 - val_loss: 2.1487 - val_accuracy: 0.2108\n",
            "Epoch 6/90\n",
            "59/59 [==============================] - 2s 28ms/step - loss: 0.1792 - accuracy: 0.9278 - val_loss: 1.3835 - val_accuracy: 0.5365\n",
            "Epoch 7/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1703 - accuracy: 0.9301 - val_loss: 0.9040 - val_accuracy: 0.6808\n",
            "Epoch 8/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1644 - accuracy: 0.9317 - val_loss: 0.5304 - val_accuracy: 0.8295\n",
            "Epoch 9/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1625 - accuracy: 0.9339 - val_loss: 0.3137 - val_accuracy: 0.8911\n",
            "Epoch 10/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1526 - accuracy: 0.9370 - val_loss: 0.2389 - val_accuracy: 0.9185\n",
            "Epoch 11/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1478 - accuracy: 0.9415 - val_loss: 0.2294 - val_accuracy: 0.9235\n",
            "Epoch 12/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1486 - accuracy: 0.9417 - val_loss: 0.2257 - val_accuracy: 0.9252\n",
            "Epoch 13/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1426 - accuracy: 0.9417 - val_loss: 0.2550 - val_accuracy: 0.9211\n",
            "Epoch 14/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1350 - accuracy: 0.9455 - val_loss: 0.2502 - val_accuracy: 0.9173\n",
            "Epoch 15/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1371 - accuracy: 0.9441 - val_loss: 0.2595 - val_accuracy: 0.9161\n",
            "Epoch 16/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1296 - accuracy: 0.9479 - val_loss: 0.2517 - val_accuracy: 0.9191\n",
            "Epoch 17/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1301 - accuracy: 0.9483 - val_loss: 0.2438 - val_accuracy: 0.9188\n",
            "Epoch 18/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1309 - accuracy: 0.9477 - val_loss: 0.2425 - val_accuracy: 0.9187\n",
            "Epoch 19/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1259 - accuracy: 0.9512 - val_loss: 0.2329 - val_accuracy: 0.9184\n",
            "Epoch 20/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1251 - accuracy: 0.9495 - val_loss: 0.2511 - val_accuracy: 0.9227\n",
            "Epoch 21/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1196 - accuracy: 0.9532 - val_loss: 0.2590 - val_accuracy: 0.9209\n",
            "Epoch 22/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1253 - accuracy: 0.9501 - val_loss: 0.2601 - val_accuracy: 0.9223\n",
            "Epoch 23/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1191 - accuracy: 0.9520 - val_loss: 0.2371 - val_accuracy: 0.9199\n",
            "Epoch 24/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1215 - accuracy: 0.9518 - val_loss: 0.2474 - val_accuracy: 0.9217\n",
            "Epoch 25/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1192 - accuracy: 0.9521 - val_loss: 0.2543 - val_accuracy: 0.9168\n",
            "Epoch 26/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1213 - accuracy: 0.9523 - val_loss: 0.2661 - val_accuracy: 0.9180\n",
            "Epoch 27/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1173 - accuracy: 0.9548 - val_loss: 0.2855 - val_accuracy: 0.9160\n",
            "Epoch 28/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1208 - accuracy: 0.9524 - val_loss: 0.2658 - val_accuracy: 0.9164\n",
            "Epoch 29/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1148 - accuracy: 0.9552 - val_loss: 0.2580 - val_accuracy: 0.9181\n",
            "Epoch 30/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1149 - accuracy: 0.9560 - val_loss: 0.2631 - val_accuracy: 0.9195\n",
            "Epoch 31/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1126 - accuracy: 0.9556 - val_loss: 0.2554 - val_accuracy: 0.9231\n",
            "Epoch 32/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1097 - accuracy: 0.9569 - val_loss: 0.2584 - val_accuracy: 0.9256\n",
            "Epoch 33/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1088 - accuracy: 0.9560 - val_loss: 0.2738 - val_accuracy: 0.9195\n",
            "Epoch 34/90\n",
            "59/59 [==============================] - 2s 34ms/step - loss: 0.1120 - accuracy: 0.9563 - val_loss: 0.2756 - val_accuracy: 0.9223\n",
            "Epoch 35/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1063 - accuracy: 0.9585 - val_loss: 0.2576 - val_accuracy: 0.9173\n",
            "Epoch 36/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1123 - accuracy: 0.9557 - val_loss: 0.2573 - val_accuracy: 0.9213\n",
            "Epoch 37/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1121 - accuracy: 0.9564 - val_loss: 0.2570 - val_accuracy: 0.9251\n",
            "Epoch 38/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1073 - accuracy: 0.9559 - val_loss: 0.3152 - val_accuracy: 0.8905\n",
            "Epoch 39/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1087 - accuracy: 0.9563 - val_loss: 0.2793 - val_accuracy: 0.9167\n",
            "Epoch 40/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1056 - accuracy: 0.9584 - val_loss: 0.2919 - val_accuracy: 0.9183\n",
            "Epoch 41/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1096 - accuracy: 0.9583 - val_loss: 0.2794 - val_accuracy: 0.9244\n",
            "Epoch 42/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1012 - accuracy: 0.9590 - val_loss: 0.2756 - val_accuracy: 0.9201\n",
            "Epoch 43/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1045 - accuracy: 0.9584 - val_loss: 0.3221 - val_accuracy: 0.9188\n",
            "Epoch 44/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1021 - accuracy: 0.9592 - val_loss: 0.3426 - val_accuracy: 0.8955\n",
            "Epoch 45/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1023 - accuracy: 0.9587 - val_loss: 0.3143 - val_accuracy: 0.9205\n",
            "Epoch 46/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1024 - accuracy: 0.9575 - val_loss: 0.3315 - val_accuracy: 0.9084\n",
            "Epoch 47/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1011 - accuracy: 0.9597 - val_loss: 0.3069 - val_accuracy: 0.9209\n",
            "Epoch 48/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0988 - accuracy: 0.9606 - val_loss: 0.3133 - val_accuracy: 0.9051\n",
            "Epoch 49/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1006 - accuracy: 0.9589 - val_loss: 0.3021 - val_accuracy: 0.9188\n",
            "Epoch 50/90\n",
            "59/59 [==============================] - 2s 28ms/step - loss: 0.1006 - accuracy: 0.9583 - val_loss: 0.2932 - val_accuracy: 0.9216\n",
            "Epoch 51/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1000 - accuracy: 0.9601 - val_loss: 0.2923 - val_accuracy: 0.9252\n",
            "Epoch 52/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1050 - accuracy: 0.9571 - val_loss: 0.3780 - val_accuracy: 0.8921\n",
            "Epoch 53/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1004 - accuracy: 0.9579 - val_loss: 0.3516 - val_accuracy: 0.9161\n",
            "Epoch 54/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0977 - accuracy: 0.9595 - val_loss: 0.3563 - val_accuracy: 0.9105\n",
            "Epoch 55/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.1045 - accuracy: 0.9569 - val_loss: 0.3387 - val_accuracy: 0.9087\n",
            "Epoch 56/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0969 - accuracy: 0.9619 - val_loss: 0.3541 - val_accuracy: 0.9087\n",
            "Epoch 57/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0964 - accuracy: 0.9605 - val_loss: 0.3290 - val_accuracy: 0.9156\n",
            "Epoch 58/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0980 - accuracy: 0.9607 - val_loss: 0.3148 - val_accuracy: 0.9204\n",
            "Epoch 59/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0941 - accuracy: 0.9615 - val_loss: 0.3099 - val_accuracy: 0.9172\n",
            "Epoch 60/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0961 - accuracy: 0.9606 - val_loss: 0.3601 - val_accuracy: 0.8991\n",
            "Epoch 61/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0944 - accuracy: 0.9614 - val_loss: 0.3427 - val_accuracy: 0.9139\n",
            "Epoch 62/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0961 - accuracy: 0.9620 - val_loss: 0.3241 - val_accuracy: 0.9229\n",
            "Epoch 63/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0976 - accuracy: 0.9610 - val_loss: 0.3748 - val_accuracy: 0.9109\n",
            "Epoch 64/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0954 - accuracy: 0.9604 - val_loss: 0.2951 - val_accuracy: 0.9237\n",
            "Epoch 65/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0961 - accuracy: 0.9613 - val_loss: 0.3383 - val_accuracy: 0.9201\n",
            "Epoch 66/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0955 - accuracy: 0.9612 - val_loss: 0.4102 - val_accuracy: 0.9051\n",
            "Epoch 67/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0977 - accuracy: 0.9598 - val_loss: 0.3527 - val_accuracy: 0.9124\n",
            "Epoch 68/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0940 - accuracy: 0.9625 - val_loss: 0.3335 - val_accuracy: 0.9156\n",
            "Epoch 69/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0952 - accuracy: 0.9607 - val_loss: 0.3521 - val_accuracy: 0.9188\n",
            "Epoch 70/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0945 - accuracy: 0.9600 - val_loss: 0.3698 - val_accuracy: 0.9161\n",
            "Epoch 71/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0917 - accuracy: 0.9626 - val_loss: 0.3291 - val_accuracy: 0.9185\n",
            "Epoch 72/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0943 - accuracy: 0.9607 - val_loss: 0.3559 - val_accuracy: 0.9141\n",
            "Epoch 73/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0904 - accuracy: 0.9641 - val_loss: 0.3565 - val_accuracy: 0.9147\n",
            "Epoch 74/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0906 - accuracy: 0.9619 - val_loss: 0.4241 - val_accuracy: 0.8741\n",
            "Epoch 75/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0891 - accuracy: 0.9642 - val_loss: 0.3796 - val_accuracy: 0.8956\n",
            "Epoch 76/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0924 - accuracy: 0.9619 - val_loss: 0.3742 - val_accuracy: 0.9127\n",
            "Epoch 77/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0930 - accuracy: 0.9628 - val_loss: 0.3456 - val_accuracy: 0.9215\n",
            "Epoch 78/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0869 - accuracy: 0.9640 - val_loss: 0.3270 - val_accuracy: 0.9175\n",
            "Epoch 79/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0950 - accuracy: 0.9618 - val_loss: 0.3721 - val_accuracy: 0.8975\n",
            "Epoch 80/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0883 - accuracy: 0.9635 - val_loss: 0.3668 - val_accuracy: 0.8967\n",
            "Epoch 81/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0863 - accuracy: 0.9642 - val_loss: 0.3818 - val_accuracy: 0.9121\n",
            "Epoch 82/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0894 - accuracy: 0.9628 - val_loss: 0.4031 - val_accuracy: 0.9153\n",
            "Epoch 83/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0881 - accuracy: 0.9641 - val_loss: 0.3831 - val_accuracy: 0.9127\n",
            "Epoch 84/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0871 - accuracy: 0.9628 - val_loss: 0.3810 - val_accuracy: 0.9036\n",
            "Epoch 85/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0888 - accuracy: 0.9627 - val_loss: 0.3836 - val_accuracy: 0.9153\n",
            "Epoch 86/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0873 - accuracy: 0.9635 - val_loss: 0.3610 - val_accuracy: 0.9171\n",
            "Epoch 87/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0902 - accuracy: 0.9621 - val_loss: 0.3363 - val_accuracy: 0.9228\n",
            "Epoch 88/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0881 - accuracy: 0.9621 - val_loss: 0.3477 - val_accuracy: 0.9139\n",
            "Epoch 89/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0862 - accuracy: 0.9633 - val_loss: 0.3887 - val_accuracy: 0.9147\n",
            "Epoch 90/90\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0876 - accuracy: 0.9638 - val_loss: 0.4017 - val_accuracy: 0.9103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe6fd5505f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y7P8jYVymBA",
        "outputId": "e68fb35f-bcd1-4e75-972d-b7dd343526bc"
      },
      "source": [
        "# evaluate model\n",
        "accuracy = model.evaluate(X_test_r, y_test, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 0s 11ms/step - loss: 0.5118 - accuracy: 0.8867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ2T7EtVymBB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}